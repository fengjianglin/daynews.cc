<!doctype html>
<html amp lang="zh-TW">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
	<script type='application/ld+json' class='yoast-schema-graph yoast-schema-graph--main'>{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://daynews.cc/#website","url":"https://daynews.cc/","name":"\u5929\u5929\u8981\u805e","description":"\u4e00\u7db2\u6253\u76e1\u5168\u7db2\u6700\u65b0\u8cc7\u8a0a\u6700\u71b1\u982d\u689d\u65b0","potentialAction":{"@type":"SearchAction","target":"https://daynews.cc/?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://daynews.cc/technology/15607#primaryimage","url":"http://p9.pstatp.com/large/pgc-image/d81f78d0582b4a698a959aef2f30af22"},{"@type":"WebPage","@id":"https://daynews.cc/technology/15607#webpage","url":"https://daynews.cc/technology/15607","inLanguage":"zh-TW","name":"\u56db\u7bc7NeurIPS 2019\u8ad6\u6587\uff0c\u5feb\u624b\u7279\u6548\u4e2d\u7684\u6a21\u578b\u58d3\u7e2e\u4e86\u89e3\u4e00\u4e0b - \u5929\u5929\u8981\u805e","isPartOf":{"@id":"https://daynews.cc/#website"},"primaryImageOfPage":{"@id":"https://daynews.cc/technology/15607#primaryimage"},"datePublished":"2019-12-13T13:45:09+00:00","dateModified":"2019-12-13T13:45:09+00:00","author":{"@id":"https://daynews.cc/#/schema/person/038ceb5ed68cf11f9ec94ba43c7ff55d"}},{"@type":["Person"],"@id":"https://daynews.cc/#/schema/person/038ceb5ed68cf11f9ec94ba43c7ff55d","name":"\u5929\u5929\u8981\u805e","image":{"@type":"ImageObject","@id":"https://daynews.cc/#authorlogo","url":"https://secure.gravatar.com/avatar/e786821a74ef0467825a7d60183307bc?s=96&d=mm&r=g","caption":"\u5929\u5929\u8981\u805e"},"sameAs":[]}]}</script>
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:description" content="機器之心報道 作者：思 從改進最優化器到多智能體團隊協力，這些最前沿的 NeurIPS 2019 研究，你都可以在快手上找到它們的身影。 在即將過去的 2019 年中，快手西雅圖實驗室在 ICLR、CVPR、AISTATS、ICML 和 NeurIPS 等頂會上發表了十多篇論文。除了這些研究方面的成果，針對實際業務，西雅圖實驗室和快手商業……" />
<meta name="twitter:title" content="四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下 - 天天要聞" />
<meta name="twitter:image" content="http://p9.pstatp.com/large/pgc-image/d81f78d0582b4a698a959aef2f30af22" />
<meta property="og:locale" content="zh_TW" />
<meta property="og:type" content="article" />
<meta property="og:title" content="四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下 - 天天要聞" />
<meta property="og:description" content="機器之心報道 作者：思 從改進最優化器到多智能體團隊協力，這些最前沿的 NeurIPS 2019 研究，你都可以在快手上找到它們的身影。 在即將過去的 2019 年中，快手西雅圖實驗室在 ICLR、CVPR、AISTATS、ICML 和 NeurIPS 等頂會上發表了十多篇論文。除了這些研究方面的成果，針對實際業務，西雅圖實驗室和快手商業……" />
<meta property="og:url" content="https://daynews.cc/technology/15607" />
<meta property="og:site_name" content="天天要聞" />
<meta property="article:section" content="科技" />
<meta property="article:published_time" content="2019-12-13T13:45:09+00:00" />
	<title>四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下 - 天天要聞</title>
		<link rel="canonical" href="https://daynews.cc/technology/15607" />
	<script type='text/javascript' src='https://cdn.ampproject.org/v0.js' async></script>
<script type='text/javascript' src='https://cdn.ampproject.org/v0/amp-analytics-0.1.js' async custom-element="amp-analytics"></script>
<style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript><meta name="generator" content="AMP Plugin v1.4.1; mode=reader; experiences=website"><meta name="generator" content="WordPress 5.2.4" />
	<style amp-custom>
		/* Generic WP styling */

.alignright {
	float: right;
}

.alignleft {
	float: left;
}

.aligncenter {
	display: block;
	text-align: center;
	margin-left: auto;
	margin-right: auto;
}

.amp-wp-enforced-sizes {
	/** Our sizes fallback is 100vw, and we have a padding on the container; the max-width here prevents the element from overflowing. **/
	max-width: 100%;
	margin: 0 auto;
}


/*
 * Prevent cases of amp-img converted from img to appear with stretching by using object-fit to scale.
 * See <https://github.com/ampproject/amphtml/issues/21371#issuecomment-475443219>.
 * Also use object-fit:contain in worst case scenario when we can't figure out dimensions for an image.
 * Additionally, in side of \AMP_Img_Sanitizer::determine_dimensions() it could $amp_img->setAttribute( 'object-fit', 'contain' )
 * so that the following rules wouldn't be needed.
 */
amp-img.amp-wp-enforced-sizes[layout="intrinsic"] > img,
amp-anim.amp-wp-enforced-sizes[layout="intrinsic"] > img {
	object-fit: contain;
}

amp-fit-text blockquote,
amp-fit-text h1,
amp-fit-text h2,
amp-fit-text h3,
amp-fit-text h4,
amp-fit-text h5,
amp-fit-text h6 {
	font-size: inherit;
}

/**
 * Override a style rule in Twenty Sixteen and Twenty Seventeen.
 * It set display:none for audio elements.
 * This selector is the same, though it adds body and uses amp-audio instead of audio.
 */
body amp-audio:not([controls]) {
	display: inline-block;
	height: auto;
}

/*
 * Style the default template messages for submit-success, submit-error, and submitting. These elements are inserted
 * by the form sanitizer when a POST form lacks the action-xhr attribute.
 */
.amp-wp-default-form-message > p {
	margin: 1em 0;
	padding: 0.5em;
}

.amp-wp-default-form-message[submitting] > p,
.amp-wp-default-form-message[submit-success] > p.amp-wp-form-redirecting {
	font-style: italic;
}

.amp-wp-default-form-message[submit-success] > p:not(.amp-wp-form-redirecting) {
	border: solid 1px #008000;
	background-color: #90ee90;
	color: #000;
}

.amp-wp-default-form-message[submit-error] > p {
	border: solid 1px #f00;
	background-color: #ffb6c1;
	color: #000;
}

/* Prevent showing empty success message in the case of an AMP-Redirect-To response header. */
.amp-wp-default-form-message[submit-success] > p:empty {
	display: none;
}

amp-carousel .amp-wp-gallery-caption {
	position: absolute;
	bottom: 0;
	left: 0;
	right: 0;
	text-align: center;
	background-color: rgba(0, 0, 0, 0.5);
	color: #fff;
	padding: 1rem;
}

.wp-block-gallery[data-amp-carousel="true"] {
	display: block;
	flex-wrap: unset;
}

/* Template Styles */

.amp-wp-content,
.amp-wp-title-bar div {
		margin: 0 auto;
	max-width: 600px;
	}

html {
	background: #0a89c0;
}

body {
	background: #fff;
	color: #353535;
	font-family: Georgia, 'Times New Roman', Times, Serif;
	font-weight: 300;
	line-height: 1.75em;
}

p,
ol,
ul,
figure {
	margin: 0 0 1em;
	padding: 0;
}

a,
a:visited {
	color: #0a89c0;
}

a:hover,
a:active,
a:focus {
	color: #353535;
}

/* Quotes */

blockquote {
	color: #353535;
	background: rgba(127,127,127,.125);
	border-left: 2px solid #0a89c0;
	margin: 8px 0 24px 0;
	padding: 16px;
}

blockquote p:last-child {
	margin-bottom: 0;
}

/* UI Fonts */

.amp-wp-meta,
.amp-wp-header div,
.amp-wp-title,
.wp-caption-text,
.amp-wp-tax-category,
.amp-wp-tax-tag,
.amp-wp-comments-link,
.amp-wp-footer p,
.back-to-top {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen-Sans", "Ubuntu", "Cantarell", "Helvetica Neue", sans-serif;
}

/* Header */

.amp-wp-header {
	background-color: #0a89c0;
}

.amp-wp-header div {
	color: #fff;
	font-size: 1em;
	font-weight: 400;
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: .875em 16px;
	position: relative;
}

.amp-wp-header a {
	color: #fff;
	text-decoration: none;
}

	.amp-wp-header .amp-wp-canonical-link {
		font-size: 0.8em;
		text-decoration: underline;
		position: absolute;
		right: 18px;	}

.amp-wp-header .amp-wp-site-icon {
	/** site icon is 32px **/
	background-color: #fff;
	border: 1px solid #fff;
	border-radius: 50%;
	position: absolute;
	right: 18px;
	top: 10px;
}

/* Article */

.amp-wp-article {
	color: #353535;
	font-weight: 400;
	margin: 1.5em auto;
	max-width: 840px;
	overflow-wrap: break-word;
	word-wrap: break-word;
}

/* Article Header */

.amp-wp-article-header {
	align-items: center;
	align-content: stretch;
	display: flex;
	flex-wrap: wrap;
	justify-content: space-between;
	margin: 1.5em 16px 0;
}

.amp-wp-title {
	color: #353535;
	display: block;
	flex: 1 0 100%;
	font-weight: 900;
	margin: 0 0 .625em;
	width: 100%;
}

/* Article Meta */

.amp-wp-meta {
	color: #696969;
	display: inline-block;
	flex: 2 1 50%;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0 0 1.5em;
	padding: 0;
}

.amp-wp-article-header .amp-wp-meta:last-of-type {
	text-align: right;
}

.amp-wp-article-header .amp-wp-meta:first-of-type {
	text-align: left;
}

.amp-wp-byline amp-img,
.amp-wp-byline .amp-wp-author {
	display: inline-block;
	vertical-align: middle;
}

.amp-wp-byline amp-img {
	border: 1px solid #0a89c0;
	border-radius: 50%;
	position: relative;
	margin-right: 6px;
}

.amp-wp-posted-on {
	text-align: right;
}

/* Featured image */

.amp-wp-article-featured-image {
	margin: 0 0 1em;
}
.amp-wp-article-featured-image amp-img {
	margin: 0 auto;
}
.amp-wp-article-featured-image.wp-caption .wp-caption-text {
	margin: 0 18px;
}

/* Article Content */

.amp-wp-article-content {
	margin: 0 16px;
}

.amp-wp-article-content ul,
.amp-wp-article-content ol {
	margin-left: 1em;
}

.amp-wp-article-content .wp-caption {
	max-width: 100%;
}

.amp-wp-article-content amp-img {
	margin: 0 auto;
}

.amp-wp-article-content amp-img.alignright {
	margin: 0 0 1em 16px;
}

.amp-wp-article-content amp-img.alignleft {
	margin: 0 16px 1em 0;
}

/* Captions */

.wp-caption {
	padding: 0;
}

.wp-caption.alignleft {
	margin-right: 16px;
}

.wp-caption.alignright {
	margin-left: 16px;
}

.wp-caption .wp-caption-text {
	border-bottom: 1px solid #c2c2c2;
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0;
	padding: .66em 10px .75em;
}

/* AMP Media */

.alignwide,
.alignfull {
	clear: both;
}

amp-carousel {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}
amp-iframe,
amp-youtube,
amp-instagram,
amp-vine {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}

.amp-wp-article-content amp-carousel amp-img {
	border: none;
}

amp-carousel > amp-img > img {
	object-fit: contain;
}

.amp-wp-iframe-placeholder {
	background: #c2c2c2 url( https://daynews.cc/wp-content/plugins/amp/assets/images/placeholder-icon.png ) no-repeat center 40%;
	background-size: 48px 48px;
	min-height: 48px;
}

/* Article Footer Meta */

.amp-wp-article-footer .amp-wp-meta {
	display: block;
}

.amp-wp-tax-category,
.amp-wp-tax-tag {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 1.5em 16px;
}

.amp-wp-comments-link {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	text-align: center;
	margin: 2.25em 0 1.5em;
}

.amp-wp-comments-link a {
	border-style: solid;
	border-color: #c2c2c2;
	border-width: 1px 1px 2px;
	border-radius: 4px;
	background-color: transparent;
	color: #0a89c0;
	cursor: pointer;
	display: block;
	font-size: 14px;
	font-weight: 600;
	line-height: 18px;
	margin: 0 auto;
	max-width: 200px;
	padding: 11px 16px;
	text-decoration: none;
	width: 50%;
	-webkit-transition: background-color 0.2s ease;
			transition: background-color 0.2s ease;
}

/* AMP Footer */

.amp-wp-footer {
	border-top: 1px solid #c2c2c2;
	margin: calc(1.5em - 1px) 0 0;
}

.amp-wp-footer div {
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: 1.25em 16px 1.25em;
	position: relative;
}

.amp-wp-footer h2 {
	font-size: 1em;
	line-height: 1.375em;
	margin: 0 0 .5em;
}

.amp-wp-footer p {
	color: #696969;
	font-size: .8em;
	line-height: 1.5em;
	margin: 0 85px 0 0;
}

.amp-wp-footer a {
	text-decoration: none;
}

.back-to-top {
	bottom: 1.275em;
	font-size: .8em;
	font-weight: 600;
	line-height: 2em;
	position: absolute;
	right: 16px;
}
		td, th {
	text-align: left;
}

a, a:active, a:visited {
	text-decoration: underline;
}

	</style>
	
	<script async custom-element="amp-auto-ads" 
			src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js"></script>
	<script async custom-element="amp-ad" src="https://cdn.ampproject.org/v0/amp-ad-0.1.js"></script>
	
</head>

<body class="">
	<amp-auto-ads type="adsense" data-ad-client="ca-pub-8261739837930821"></amp-auto-ads>

<header id="top" class="amp-wp-header">
	<div>
		<a href="https://daynews.cc/">
									<span class="amp-site-title">
				天天要聞			</span>
		</a>

										<a class="amp-wp-canonical-link" href="https://daynews.cc/technology/15607">
				原網頁			</a>
			</div>
</header>

<article class="amp-wp-article">
	<header class="amp-wp-article-header">
		<h1 class="amp-wp-title">四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下</h1>
			<div class="amp-wp-meta amp-wp-byline">
					<amp-img src="https://daynews.cc/wp-content/themes/Kratos/images/default_avatar.jpeg" alt="天天要聞" width="24" height="24" layout="fixed"></amp-img>
				<span class="amp-wp-author author vcard">天天要聞</span>
	</div>
<div class="amp-wp-meta amp-wp-posted-on">
	<time datetime="2019-12-13T21:45:09+00:00">
		2019-12-13	</time>
</div>
	</header>

	
	<div class="amp-wp-article-content">
		<amp-ad width="100vw" height="320"
			 type="adsense"
			 data-ad-client="ca-pub-8261739837930821"
			 data-ad-slot="2502207318"
			 data-auto-format="rspv"
			 data-full-width="">
		  <div overflow=""></div>
		</amp-ad>
		
		<div>
<p>機器之心報道</p>
<p><strong>作者：思</strong></p>
<blockquote class="js_blockquote_wrap">
<p>從改進最優化器到多智能體團隊協力，這些最前沿的 NeurIPS 2019 研究，你都可以在快手上找到它們的身影。</p>
</blockquote>
<p>在即將過去的 2019 年中，快手西雅圖實驗室在 ICLR、CVPR、AISTATS、ICML 和 NeurIPS 等頂會上發表了十多篇論文。<br>除了這些研究方面的成果，針對實際業務，西雅圖實驗室和快手商業化還推出了基於 GPU 的廣告推薦訓練系統 Persia，採用這樣的訓練系統單機能提升 640 倍的效率，已經在業務場景中廣泛使用；此外提出的新演算法對商業化廣告收益也有大量提升，新技術在視頻風格遷移和遊戲業務中也有多項落地成果。這是快手西雅圖實驗室在 2019 交出的一份成績單。</p>

<p>那麼在 NeurIPS 2019，在模型壓縮領域，快手短視頻最新應用的技術是什麼樣的？我們在應用各種視覺特效時，為什麼以龐大著稱的深度神經網路能滿足我們的要求？在本文中，機器之心將介紹快手在 NeurIPS 2019 的四篇研究成果，並重點探討他們在模型壓縮方面的努力。<br>下面是本文的目錄，我們將以如下結構介紹這四項研究成果：</p>
<ul class=" list-paddingleft-2">
<li>快手在 NeurIPS 2019</li>
<li>在快手做研究</li>
<ul class=" list-paddingleft-2">
<li>研究框架用什麼？</li>
<li>論文代碼要開源？</li>
</ul>
<li>模型壓縮在快手</li>
<ul class=" list-paddingleft-2">
<li>模型壓縮這條邏輯線</li>
</ul>
<li>優化器：「有些參數生而冗餘」</li>
<ul class=" list-paddingleft-2">
<li>從數學看優化器</li>
</ul>
<li>對抗訓練：「我也能變壓縮」</li>
<ul class=" list-paddingleft-2">
<li>從數學看對抗與壓縮</li>
</ul>
</ul>
<p><strong>快手在 NeurIPS 2019</strong></p>

<p>在最近的 NeurIPS 2019 中，快手及合作者展示了四項新研究。這四項研究中有三項已經或者正在應用到實際業務中，例如第一篇跟 University of Rochester 和 TAMU 合作的模型壓縮的工作，它已經應用到一些 CV 任務中，包括快手比較炫酷的風格遷移。</p>

<p>第二篇模型壓縮更像新方法方面的探索，它也能用於部分應用而加速視頻的處理過程。第三篇強化學習正應用於遊戲 AI，它可以令智能體學會「團隊協作」。</p>

<ul class=" list-paddingleft-2">
<li>論文：Adversarially Trained Model Compression: When Robustness Meets Efﬁciency</li>
<li>地址：https://papers.nips.cc/paper/8410-model-compression-with-adversarial-robustness-a-unified-optimization-framework</li>
</ul>
<ul class=" list-paddingleft-2">
<li>論文：Global Sparse Momentum SGD for Pruning Very Deep Neural Networks</li>
<li>地址：https://papers.nips.cc/paper/8867-global-sparse-momentum-sgd-for-pruning-very-deep-neural-networks</li>
</ul>
<ul class=" list-paddingleft-2">
<li>論文：LIIR: Learning Individual Intrinsic Reward in Multi-Agent Reinforcement Learning</li>
<li>地址：https://papers.nips.cc/paper/8691-liir-learning-individual-intrinsic-reward-in-multi-agent-reinforcement-learning</li>
</ul>
<ul class=" list-paddingleft-2">
<li>論文：Efﬁcient Smooth Non-Convex Stochastic Compositional Optimization via Stochastic Recursive Gradient Descent</li>
<li>地址：https://papers.nips.cc/paper/8916-efficient-smooth-non-convex-stochastic-compositional-optimization-via-stochastic-recursive-gradient-descent</li>
</ul>
<p>當然，這些研究成果是快手與合作者聯合完成的，例如第二篇模型壓縮就是清華大學-快手未來媒體數據聯合研究院以及快手西雅圖實驗室共同完成的。</p>

<p>快手西雅圖實驗室負責人劉霽表示：「這四項研究都有其獨特的亮點。在第一篇對抗訓練的模型壓縮中，它會<strong>把各種壓縮方法都集中到一起，並做一種聯合優化</strong>，這和之前按照 Pipeline 的形式單獨做壓縮有很大的不同。與此同時，模型還能抵禦對抗性攻擊，這是兩個比較有意思的思路。」</p>

<p>「一般剪枝方法都需要大量調參以更好地保留模型性能，而全局稀疏動量 SGD 會端到端地學習到底哪些權重比較重要，重要的就少壓縮一點，不重要的就多壓縮一點。」，論文合著者，清華大學軟體學院副院長丁貴廣說，「第二篇論文的核心思想在於，我們<strong>給定一個壓縮率，模型在訓練中就能自己剪裁</strong>，並滿足這個壓縮率。」</p>

<p>「對於第三篇多智能體強化學習是跟騰訊 AI Lab 和 Robotics X 合作，它希望<strong>智能體能快速學會利用自己所觀測的信息來相互配合</strong>。比如說在星際爭霸中，我們發現確實會產生多智能體合作的現象，模型會讓一些防高血厚的單位去抗對方的輸出，己方輸出高的單元會躲到後方攻擊。」，劉霽說。<br>「雖然把所有的 agents 看成是一個 agent，理論上也可以學到最終的配合效果，但是效率會非常低，不具有可擴展性。我們的方法通過一種 intrinsic reward 的機制兼顧了可擴展性和效率，通過鼓勵每個 agent 按照單體利益最大化的原則去學習自己的 policy，然後這種 intrinsic reward 的影響會越來越小最後快速達到學到整體最後的方案」，劉霽說。</p>

<div class="pgc-img">
  <amp-img src="http://p9.pstatp.com/large/pgc-image/d81f78d0582b4a698a959aef2f30af22" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="640" height="270" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p9.pstatp.com/large/pgc-image/d81f78d0582b4a698a959aef2f30af22" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="640" height="270" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>受傷的智能體 2 躲入血厚的智能體背後，並繼續輸出傷害。</p>

<p>「最後第四篇是與騰訊 AI Lab 合作的更偏理論的一項研究，它是針對<strong>複合函數的最優化方法</strong>。這裡複合指的是一個數學期望函數中複合了另一個數學期望，而常規的 ML 目標函數就只有最外面一個數學期望。」，劉霽說，「這種最優化方法在風險管理或 RL 中非常有用，例如在 RL 中解貝爾曼方程，它本質上就是複合函數最優化問題。」</p>

<p><strong>在快手做研究</strong></p>

<p>在快手做研究，數據與算力並不是難事，實習生在授權條件下也能拿到很多一手脫敏數據。在快手做研究，從 Idea 到模型上線這條鏈路非常短，<strong>研究者能很快看到實驗室結果對產品的影響</strong>。</p>

<p>因為鏈路短，研究者很容易接觸一手的線上反饋，這一點特別重要。劉霽說：「我認為最好的研究工作一定是從現實場景與反饋中生成出來的，因此我們做的解決方案、理論分析或演算法升級才能真正服務於某個具體的問題。」</p>

<p>清華大學軟體學院副院長丁貴廣也表明，「清華大學軟體學院與快手聯合建立了未來媒體數據聯合研究院，其研究方向主要圍繞著快手短視頻業務以及未來媒體。我們的合作研究很多都和媒體任務相關，快手會提供很多技術需求與對應的資源。」正因為研究與應用之間的路徑非常短，新研究才能更快得到迭代。</p>

<p>在快手做研究應該會很有意思，機器之心也比較好奇做研究的框架或開源策略都是什麼樣的。為此，下面我們可以從兩方面一瞥快手研究者的思路。</p>

<p><strong>研究框架用什麼？</strong></p>

<p>「這當然會分場景，對於 CV 研究來說，PyTorch 或 TensorFlow 開源框架是足夠的。但是對於產品，我們新成立的 AI 平台部門則主要致力於提供一些通用化的機器學習和深度學習的工具，它會為不同的業務優化一些底層技術。」，劉霽說。</p>

<p>對於研究框架，新入職的博士同學說：「TensorFlow 2.0 嘗試構建易於使用的動態圖編程，但 1.X 的很多歷史包袱也要支持，因此整體上很難做到統一。此外，TensorFlow 1.X 暴露了過多不需要關心的 API，而 2.0 目前又存在很多問題。所以，做研究我更喜歡用 PyTorch。」</p>

<p><strong>論文代碼要開源？</strong></p>

<p>在快手研究者的眼中，開源是一件很重要的事，但好的研究成果並不一定需要通過開源來體現。</p>

<p>「首先，開源代碼對研究肯定是一件有益的事，能極大方便同行的研究做比較。但與此同時，能夠復現結果的代碼，並不一定表示其方法有價值，這兩者並不一定是絕對的相關性。」，劉霽說，「我個人認為，好方法並不一定需要實驗來輔證，它們本身就有足夠深遠的洞見。大家在看實驗之前就能預見它在哪些條件下能 Work，這樣的研究就是非常有價值的。」</p>

<p>有了眾多資源與研究經驗，西雅圖實驗室才能持續地針對某個研究領域做出重要貢獻。這裡有一個例子，那就是模型壓縮，西雅圖實驗室今年在這個領域已經發了 4 篇頂會論文。</p>

<p><strong>模型壓縮在快手</strong></p>

<p>從今年 ICLR、CVPR 到正在進行中的 NeurIPS，快手西雅圖實驗室及合作者探索了很多模型壓縮方法。這些方法從不同的維度解決深度學習應用問題，例如降低模型能耗、創新壓縮演算法、聯合優化壓縮演算法等等。</p>

<p>「快手的應用平台大多都體現在手機上，很多模型與演算法都要部署到手機端，因此功耗、實時響應都非常重要。<strong>模型的應用價值，首先在於它的延遲、能耗等指標滿足要求，其次才著重提高準確率。</strong>」，劉霽說，「除了移動端的應用，雲端也需要模型壓縮。當模型非常大，推斷效率就很低，這不僅影響服務效果，同時伺服器也容易宕機。」</p>

<p>目前快手針對不同手機型號會單獨考慮壓縮演算法，但很快就會將這些前沿的壓縮演算法都會做成 API，並用於更廣泛的壓縮。劉霽表示：「應用模型壓縮最困難的地方在於打通鏈路，從底層硬體、壓縮演算法到部署到實際產品，我們需要理解每一個環節，然後再完成整體的聯合優化。」</p>

<p><strong>模型壓縮這條邏輯線</strong></p>

<p>之前機器之心曾介紹過「</p>
<p>快手有的放矢的模型壓縮</p>
<p>」，它以硬體能耗為目標進行剪枝等操作，並期待構建最節能的深度學習模型。在近日舉辦的 NeurIPS 2019 中，快手及合作者又在另外兩方面探討模型壓縮的新可能：修改最優化器以「自動」剪枝模型權重、聯合不同的壓縮演算法以學習怎樣組合最合適。</p>

<p>「今年 4 篇模型壓縮方面的頂會論文是有一條邏輯線的，我們從不同的維度來提升模型壓縮的效果。」，劉霽說，「之前 ICLR 與 CVPR 2019 的研究主要是利用對硬體的建模指導模型壓縮，後面第一篇嘗試對各種壓縮方法做一個聯合優化，第二篇則探索最優化方法本身的效果。這三者分別從不同的維度探索模型壓縮，它們是可以聯合的。」</p>

<p>現在，讓我們看看快手及合作者在 NeurIPS 2019 完成的兩項模型壓縮研究，它們的核心思想都非常有價值。</p>

<p><strong>優化器：「有些參數生而冗餘」</strong></p>

<p>剪枝在模型壓縮中非常常見，我們訓練模型後，可以根據某些標準刪除一些不重要的權重。但通常情況下，這種裁剪會造成精度損失，所以需要重新微調模型。那麼有沒有辦法在訓練中就完成剪枝，讓模型在剪枝率的約束下進行學習？<strong>我們可以把剪枝嵌入到最優化器內，讓模型不再更新「生而冗餘」的權重</strong>。</p>

<p>對於直接學習緊湊的網路，最直觀的思路是，對於那些「重要的」權重，我們使用優化器更新，而對於那些「不重要」的權重，那就讓它們衰減到零吧。思想很簡單，但問題是，什麼是重要的，什麼又是不重要的權重？這就是這篇論文該解決的問題。</p>

<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/a121ebc1f2d241298e3d1f390c5aa7f3" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="640" height="319" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/a121ebc1f2d241298e3d1f390c5aa7f3" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="640" height="319" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>在這一篇論文中，研究者提出了名為全局稀疏動量 SGD 的方法（GSM），該演算法<strong>直接修改梯度流來進行 DNN 剪枝</strong>。在每一次訓練迭代中，一般 SGD 用目標函數求得的梯度來更新所有參數，然而在 GSM 中，只有較為重要的少數參數用目標函數的梯度來更新（稱為「活性更新」），大多數參數只用權值衰減來進行更新（稱為「負向更新」）。<br>這樣，隨著訓練的進行，大多數參數都會變得無限接近於 0。因而，當訓練結束後，去除這些無限接近 0 的參數不會對網路的精度產生影響。</p>

<p>這種從優化器出發的剪枝方法有非常好的屬性：</p>

<ul class=" list-paddingleft-2">
<li><strong>自動發現每層合適的稀疏率</strong>：如果 DNN 中的某一層對剪枝比較敏感，GSM 會對該層權重執行更「輕」的剪裁。也就是說，給定全局壓縮率作為唯一目標，GSM 能夠根據每層的敏感性自動選擇合適的剪枝比率。</li>
<li><strong>發現更好的 winning lottery tickets</strong>：ICLR 2019 最佳論文 The Lottery Ticket Hypothesis 表明，如果有些參數在訓練後的網路中顯得很「重要」，它們很可能在隨機初始化後就是「重要」的。即在初始化的網路中存在某些稀疏子結構，單獨訓練這樣的子結構可以得到與訓練整個網路相媲美的性能，GSM 就能找到更好的稀疏子結構。</li>
</ul>
<p><strong>從數學看優化器</strong></p>

<p>好了，該看看 GSM 的具體過程了，一般帶動量的 SGD 如下所示，它會先計算一個累積的梯度，可以直觀理解為下降小球的「慣性」。學習演算法會根據這樣的慣性找到更新方向，並更新對應的權重。</p>

<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/0f69b967f38845b58f6243e4089ef620" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="1080" height="164" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/0f69b967f38845b58f6243e4089ef620" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="1080" height="164" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>GSM 首先要決定對哪些參數進行「活性更新」，這就要求度量在一次迭代中每個參數對於模型的重要性。這樣的重要性度量可以表示為：</p>

<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/b4a11e2f729f47db8f951434da006438" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="1080" height="230" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/b4a11e2f729f47db8f951434da006438" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="1080" height="230" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>其中 Θ 表示模型的所有參數，如果權重的梯度小或者權重本身小，那麼 T 值肯定很小，這個權重就不是重要的。我們可以根據全局壓縮率為 P 以及剛算出來的 T 來選擇更新哪些權重，具體而言，<strong>總參數量的 1/P 是需要更新的，因此對於 T 值最大的 1/P 個參數進行更新</strong>，其它參數執行權重衰減就行了。</p>

<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/7d1e416f799a45edb59c8e110823d2a9" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="1080" height="151" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/7d1e416f799a45edb59c8e110823d2a9" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="1080" height="151" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>如上將 T 應用到方程 1 就能得到 GSM 更新式。B 矩陣中只有 1/P 的值為 1，其它為 0，它再與梯度矩陣執行對應元素相乘就表明，模型只會採用梯度更新這 1/P 的參數。<br><strong>對抗訓練：「我也能變壓縮」</strong></p>

<p>現在我們從另一個角度，看看怎樣統一模型緊湊性與魯棒性，怎樣聯合不同的壓縮方法。也就是說，我們要保證壓縮過後的模型具有足夠小，且該模型還能抵禦來自於對抗樣本的攻擊。</p>

<p>為了同時兼顧模型的魯棒性和緊湊性，研究者提出了一個全新的對抗訓練模型壓縮演算法（ATMC）。該方法同時囊括了剪枝和量化方法，並且將模型壓縮作為對抗性訓練的約束條件，從而得到滿足壓縮約束的模型。<br>在研究者的實驗中，ATMC 壓縮後的模型在壓縮比例、泛化能力和模型魯棒性之間達到了較好的平衡。</p>

<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/d8c6bfe57f394e77b573bc7cd57017e7" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="640" height="404" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/d8c6bfe57f394e77b573bc7cd57017e7" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="640" height="404" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>ATMC 演算法的優點在於，它首次通過聯合訓練實現了魯棒性與緊湊性兼顧，它可以將大規模模型壓縮為更穩健的小模型。它的三大特點在於：</p>

<ul class=" list-paddingleft-2">
<li>ATMC 以對抗性訓練問題作為優化目標（極小化極大優化問題）；</li>
<li>研究者將結構化的權重分解、元素級的稀疏化剪枝、以及模型權重量化作為整個優化問題的約束；</li>
<li>研究者證明 ADMM 演算法可以有效解決帶有約束的極小化極大優化問題，並得到具有緊湊性和魯棒性的模型。</li>
</ul>
<p><strong>從數學看對抗與壓縮</strong></p>

<p>對於對抗訓練，研究者將其作為 ATMC 的優化目標，這是一個極小極大化問題。首先通過白盒攻擊，攻擊者通過這些竊聽權重、架構等信息，生成一個能最大程度欺騙模型的對抗性樣本。隨後作為防禦者，它會最小化模型在對抗樣本出錯的概率，從而變得更穩健。這種極小極大地對抗訓練，其實思想和生成對抗網路比較像。</p>

<p>具體的，這種對抗性訓練目標可以表示為如下兩個方程，即最大化錯誤以獲得對抗樣本，最小化錯誤以獲得準確的模型。</p>

<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/b12066651532433eab2a3f5d5acb944a" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="640" height="289" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/b12066651532433eab2a3f5d5acb944a" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="640" height="289" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>其次對於聯合模型壓縮，研究者<strong>將剪枝、權重分解和量化作為上述優化目標的約束條件</strong>，希望模型在控制大小的情況學習如何變得準確與穩健。值得注意的是，所有優化約束僅包含兩個超參數，ATMC 將根據對壓縮性和魯棒性的需求自動地調整每層權重的稀疏性。</p>

<p>如下所示分別為權重分解、剪枝和量化三種約束條件。權重 W 為某個卷積層的權重矩陣，<strong>權重分解相當於通道級的剪枝演算法、剪枝相當於元素級的裁剪方法</strong>。在考慮模型修剪的壓縮方法的同時，研究者也引入了權重量化方法來進行模型壓縮，即給定每層參數的比特寬度，並根據每層的具體情況計算量化字典。</p>

<div class="pgc-img">
  <amp-img src="http://p9.pstatp.com/large/pgc-image/bb7f0ed9359c4547ace58a263acc2264" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="640" height="254" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p9.pstatp.com/large/pgc-image/bb7f0ed9359c4547ace58a263acc2264" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="640" height="254" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>結合這兩大模塊，我們就可以得到 ATMC 框架的整體優化目標：</p>

<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/ffcea4c452284d56806f14faf9f94559" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="845" height="200" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/ffcea4c452284d56806f14faf9f94559" alt="《四篇NeurIPS 2019論文，快手特效中的模型壓縮了解一下》" width="845" height="200" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>這個目標函數看起來很複雜，極小極大化優化目標也就算了，還帶有兩組約束條件，似乎常見的優化器都無能為力了。至於如何解這樣帶約束的優化目標，那又是外一個很有意思的話題了。讀者可以參考原論文或者之前基於能耗的模型壓縮方法，看看 <strong>ADMM 優化框架如何解這類帶約束的最優化問題</strong>。</p>

<p>最後，除了各種壓縮演算法，本身更緊湊的模型也是非常重要的一個方向，從最近 Quoc V. Le 等研究者的 EfficientNet 與 EfficientDet 就能明顯感覺到。總的來說，深度學習想要應用，模型的計算要求還是最為關鍵的那一類問題。</p>
</div>
	</div>

	<footer class="amp-wp-article-footer">
			<div class="amp-wp-meta amp-wp-tax-category">
		分類: <a href="https://daynews.cc/technology" rel="category tag">科技</a>	</div>

		<div class="amp-wp-meta amp-wp-comments-link">
		<a href="https://daynews.cc/technology/15607#comments">
			寫評論		</a>
	</div>
	</footer>
</article>

<footer class="amp-wp-footer">
	<div>
		<h2>天天要聞</h2>
		<a href="#top" class="back-to-top">返回頂部</a>
	</div>
</footer>


<amp-analytics id="4c2faa84438c" type="gtag"><script type="application/json">{"vars":{"gtag_id":"UA-154709495-1","config":{"UA-154709495-1":{"groups":"default"}}}}</script></amp-analytics>
</body>
</html>
<!-- This is the static html file -->