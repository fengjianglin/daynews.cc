<!doctype html>
<html amp lang="zh-TW">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
	<script type='application/ld+json' class='yoast-schema-graph yoast-schema-graph--main'>{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://daynews.cc/#website","url":"https://daynews.cc/","name":"\u5929\u5929\u8981\u805e","description":"\u4e00\u7db2\u6253\u76e1\u5168\u7db2\u6700\u65b0\u8cc7\u8a0a\u6700\u71b1\u982d\u689d\u65b0","potentialAction":{"@type":"SearchAction","target":"https://daynews.cc/?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://daynews.cc/technology/26921/#primaryimage","url":"http://p1.pstatp.com/large/pgc-image/f899ea52b67d40e1b77a0dab3ccc00ec"},{"@type":"WebPage","@id":"https://daynews.cc/technology/26921/#webpage","url":"https://daynews.cc/technology/26921/","inLanguage":"zh-TW","name":"\u4f55\u6137\u660e\u5718\u968a\u53c8\u51fa\u795e\u4f5c\uff1a\u5c07\u5716\u50cf\u5206\u5272\u8996\u4f5c\u6e32\u67d3\u554f\u984c\uff0c\u6027\u80fd\u986f\u8457\u63d0\u5347 - \u5929\u5929\u8981\u805e","isPartOf":{"@id":"https://daynews.cc/#website"},"primaryImageOfPage":{"@id":"https://daynews.cc/technology/26921/#primaryimage"},"datePublished":"2019-12-20T09:05:12+00:00","dateModified":"2019-12-20T09:05:12+00:00","author":{"@id":"https://daynews.cc/#/schema/person/038ceb5ed68cf11f9ec94ba43c7ff55d"}},{"@type":["Person"],"@id":"https://daynews.cc/#/schema/person/038ceb5ed68cf11f9ec94ba43c7ff55d","name":"\u5929\u5929\u8981\u805e","image":{"@type":"ImageObject","@id":"https://daynews.cc/#authorlogo","url":"https://secure.gravatar.com/avatar/e786821a74ef0467825a7d60183307bc?s=96&d=mm&r=g","caption":"\u5929\u5929\u8981\u805e"},"sameAs":[]}]}</script>
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:description" content="Facebook人工智慧實驗室Alexander Kirillov、吳育昕、何愷明、Ross Girshick等研究人員近日發表新論文，提出一種高效、高質量的目標和場景圖像分割新方法。 通過將有效渲染的經典計算機圖形學方法與像素標記任務中遇到的過採樣和欠採樣問題進行類比，他們開發了一個獨特的視角，將圖像分割視為一個渲染問題。 從這個角度出……" />
<meta name="twitter:title" content="何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升 - 天天要聞" />
<meta name="twitter:image" content="http://p1.pstatp.com/large/pgc-image/f899ea52b67d40e1b77a0dab3ccc00ec" />
<meta property="og:locale" content="zh_TW" />
<meta property="og:type" content="article" />
<meta property="og:title" content="何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升 - 天天要聞" />
<meta property="og:description" content="Facebook人工智慧實驗室Alexander Kirillov、吳育昕、何愷明、Ross Girshick等研究人員近日發表新論文，提出一種高效、高質量的目標和場景圖像分割新方法。 通過將有效渲染的經典計算機圖形學方法與像素標記任務中遇到的過採樣和欠採樣問題進行類比，他們開發了一個獨特的視角，將圖像分割視為一個渲染問題。 從這個角度出……" />
<meta property="og:url" content="https://daynews.cc/technology/26921/" />
<meta property="og:site_name" content="天天要聞" />
<meta property="article:section" content="科技" />
<meta property="article:published_time" content="2019-12-20T09:05:12+00:00" />
	<title>何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升 - 天天要聞</title>
		<link rel="canonical" href="https://daynews.cc/technology/26921/" />
	<script type='text/javascript' src='https://cdn.ampproject.org/v0.js' async></script>
<script type='text/javascript' src='https://cdn.ampproject.org/v0/amp-analytics-0.1.js' async custom-element="amp-analytics"></script>
<style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript><meta name="generator" content="AMP Plugin v1.4.1; mode=reader; experiences=website"><meta name="generator" content="WordPress 5.2.4" />
	<style amp-custom>
		/* Generic WP styling */

.alignright {
	float: right;
}

.alignleft {
	float: left;
}

.aligncenter {
	display: block;
	text-align: center;
	margin-left: auto;
	margin-right: auto;
}

.amp-wp-enforced-sizes {
	/** Our sizes fallback is 100vw, and we have a padding on the container; the max-width here prevents the element from overflowing. **/
	max-width: 100%;
	margin: 0 auto;
}


/*
 * Prevent cases of amp-img converted from img to appear with stretching by using object-fit to scale.
 * See <https://github.com/ampproject/amphtml/issues/21371#issuecomment-475443219>.
 * Also use object-fit:contain in worst case scenario when we can't figure out dimensions for an image.
 * Additionally, in side of \AMP_Img_Sanitizer::determine_dimensions() it could $amp_img->setAttribute( 'object-fit', 'contain' )
 * so that the following rules wouldn't be needed.
 */
amp-img.amp-wp-enforced-sizes[layout="intrinsic"] > img,
amp-anim.amp-wp-enforced-sizes[layout="intrinsic"] > img {
	object-fit: contain;
}

amp-fit-text blockquote,
amp-fit-text h1,
amp-fit-text h2,
amp-fit-text h3,
amp-fit-text h4,
amp-fit-text h5,
amp-fit-text h6 {
	font-size: inherit;
}

/**
 * Override a style rule in Twenty Sixteen and Twenty Seventeen.
 * It set display:none for audio elements.
 * This selector is the same, though it adds body and uses amp-audio instead of audio.
 */
body amp-audio:not([controls]) {
	display: inline-block;
	height: auto;
}

/*
 * Style the default template messages for submit-success, submit-error, and submitting. These elements are inserted
 * by the form sanitizer when a POST form lacks the action-xhr attribute.
 */
.amp-wp-default-form-message > p {
	margin: 1em 0;
	padding: 0.5em;
}

.amp-wp-default-form-message[submitting] > p,
.amp-wp-default-form-message[submit-success] > p.amp-wp-form-redirecting {
	font-style: italic;
}

.amp-wp-default-form-message[submit-success] > p:not(.amp-wp-form-redirecting) {
	border: solid 1px #008000;
	background-color: #90ee90;
	color: #000;
}

.amp-wp-default-form-message[submit-error] > p {
	border: solid 1px #f00;
	background-color: #ffb6c1;
	color: #000;
}

/* Prevent showing empty success message in the case of an AMP-Redirect-To response header. */
.amp-wp-default-form-message[submit-success] > p:empty {
	display: none;
}

amp-carousel .amp-wp-gallery-caption {
	position: absolute;
	bottom: 0;
	left: 0;
	right: 0;
	text-align: center;
	background-color: rgba(0, 0, 0, 0.5);
	color: #fff;
	padding: 1rem;
}

.wp-block-gallery[data-amp-carousel="true"] {
	display: block;
	flex-wrap: unset;
}

/* Template Styles */

.amp-wp-content,
.amp-wp-title-bar div {
		margin: 0 auto;
	max-width: 600px;
	}

html {
	background: #0a89c0;
}

body {
	background: #fff;
	color: #353535;
	font-family: Georgia, 'Times New Roman', Times, Serif;
	font-weight: 300;
	line-height: 1.75em;
}

p,
ol,
ul,
figure {
	margin: 0 0 1em;
	padding: 0;
}

a,
a:visited {
	color: #0a89c0;
}

a:hover,
a:active,
a:focus {
	color: #353535;
}

/* Quotes */

blockquote {
	color: #353535;
	background: rgba(127,127,127,.125);
	border-left: 2px solid #0a89c0;
	margin: 8px 0 24px 0;
	padding: 16px;
}

blockquote p:last-child {
	margin-bottom: 0;
}

/* UI Fonts */

.amp-wp-meta,
.amp-wp-header div,
.amp-wp-title,
.wp-caption-text,
.amp-wp-tax-category,
.amp-wp-tax-tag,
.amp-wp-comments-link,
.amp-wp-footer p,
.back-to-top {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen-Sans", "Ubuntu", "Cantarell", "Helvetica Neue", sans-serif;
}

/* Header */

.amp-wp-header {
	background-color: #0a89c0;
}

.amp-wp-header div {
	color: #fff;
	font-size: 1em;
	font-weight: 400;
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: .875em 16px;
	position: relative;
}

.amp-wp-header a {
	color: #fff;
	text-decoration: none;
}

	.amp-wp-header .amp-wp-canonical-link {
		font-size: 0.8em;
		text-decoration: underline;
		position: absolute;
		right: 18px;	}

.amp-wp-header .amp-wp-site-icon {
	/** site icon is 32px **/
	background-color: #fff;
	border: 1px solid #fff;
	border-radius: 50%;
	position: absolute;
	right: 18px;
	top: 10px;
}

/* Article */

.amp-wp-article {
	color: #353535;
	font-weight: 400;
	margin: 1.5em auto;
	max-width: 840px;
	overflow-wrap: break-word;
	word-wrap: break-word;
}

/* Article Header */

.amp-wp-article-header {
	align-items: center;
	align-content: stretch;
	display: flex;
	flex-wrap: wrap;
	justify-content: space-between;
	margin: 1.5em 16px 0;
}

.amp-wp-title {
	color: #353535;
	display: block;
	flex: 1 0 100%;
	font-weight: 900;
	margin: 0 0 .625em;
	width: 100%;
}

/* Article Meta */

.amp-wp-meta {
	color: #696969;
	display: inline-block;
	flex: 2 1 50%;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0 0 1.5em;
	padding: 0;
}

.amp-wp-article-header .amp-wp-meta:last-of-type {
	text-align: right;
}

.amp-wp-article-header .amp-wp-meta:first-of-type {
	text-align: left;
}

.amp-wp-byline amp-img,
.amp-wp-byline .amp-wp-author {
	display: inline-block;
	vertical-align: middle;
}

.amp-wp-byline amp-img {
	border: 1px solid #0a89c0;
	border-radius: 50%;
	position: relative;
	margin-right: 6px;
}

.amp-wp-posted-on {
	text-align: right;
}

/* Featured image */

.amp-wp-article-featured-image {
	margin: 0 0 1em;
}
.amp-wp-article-featured-image amp-img {
	margin: 0 auto;
}
.amp-wp-article-featured-image.wp-caption .wp-caption-text {
	margin: 0 18px;
}

/* Article Content */

.amp-wp-article-content {
	margin: 0 16px;
}

.amp-wp-article-content ul,
.amp-wp-article-content ol {
	margin-left: 1em;
}

.amp-wp-article-content .wp-caption {
	max-width: 100%;
}

.amp-wp-article-content amp-img {
	margin: 0 auto;
}

.amp-wp-article-content amp-img.alignright {
	margin: 0 0 1em 16px;
}

.amp-wp-article-content amp-img.alignleft {
	margin: 0 16px 1em 0;
}

/* Captions */

.wp-caption {
	padding: 0;
}

.wp-caption.alignleft {
	margin-right: 16px;
}

.wp-caption.alignright {
	margin-left: 16px;
}

.wp-caption .wp-caption-text {
	border-bottom: 1px solid #c2c2c2;
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0;
	padding: .66em 10px .75em;
}

/* AMP Media */

.alignwide,
.alignfull {
	clear: both;
}

amp-carousel {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}
amp-iframe,
amp-youtube,
amp-instagram,
amp-vine {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}

.amp-wp-article-content amp-carousel amp-img {
	border: none;
}

amp-carousel > amp-img > img {
	object-fit: contain;
}

.amp-wp-iframe-placeholder {
	background: #c2c2c2 url( https://daynews.cc/wp-content/plugins/amp/assets/images/placeholder-icon.png ) no-repeat center 40%;
	background-size: 48px 48px;
	min-height: 48px;
}

/* Article Footer Meta */

.amp-wp-article-footer .amp-wp-meta {
	display: block;
}

.amp-wp-tax-category,
.amp-wp-tax-tag {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 1.5em 16px;
}

.amp-wp-comments-link {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	text-align: center;
	margin: 2.25em 0 1.5em;
}

.amp-wp-comments-link a {
	border-style: solid;
	border-color: #c2c2c2;
	border-width: 1px 1px 2px;
	border-radius: 4px;
	background-color: transparent;
	color: #0a89c0;
	cursor: pointer;
	display: block;
	font-size: 14px;
	font-weight: 600;
	line-height: 18px;
	margin: 0 auto;
	max-width: 200px;
	padding: 11px 16px;
	text-decoration: none;
	width: 50%;
	-webkit-transition: background-color 0.2s ease;
			transition: background-color 0.2s ease;
}

/* AMP Footer */

.amp-wp-footer {
	border-top: 1px solid #c2c2c2;
	margin: calc(1.5em - 1px) 0 0;
}

.amp-wp-footer div {
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: 1.25em 16px 1.25em;
	position: relative;
}

.amp-wp-footer h2 {
	font-size: 1em;
	line-height: 1.375em;
	margin: 0 0 .5em;
}

.amp-wp-footer p {
	color: #696969;
	font-size: .8em;
	line-height: 1.5em;
	margin: 0 85px 0 0;
}

.amp-wp-footer a {
	text-decoration: none;
}

.back-to-top {
	bottom: 1.275em;
	font-size: .8em;
	font-weight: 600;
	line-height: 2em;
	position: absolute;
	right: 16px;
}
		td, th {
	text-align: left;
}

a, a:active, a:visited {
	text-decoration: underline;
}

	</style>
	
</head>

<body class="">


<header id="top" class="amp-wp-header">
	<div>
		<a href="https://daynews.cc/">
									<span class="amp-site-title">
				天天要聞			</span>
		</a>

										<a class="amp-wp-canonical-link" href="https://daynews.cc/technology/26921/">
				原網頁			</a>
			</div>
</header>

<article class="amp-wp-article">
	<header class="amp-wp-article-header">
		<h1 class="amp-wp-title">何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升</h1>
			<div class="amp-wp-meta amp-wp-byline">
					<amp-img src="https://daynews.cc/wp-content/themes/Kratos/images/default_avatar.jpeg" alt="天天要聞" width="24" height="24" layout="fixed"></amp-img>
				<span class="amp-wp-author author vcard">天天要聞</span>
	</div>
<div class="amp-wp-meta amp-wp-posted-on">
	<time datetime="2019-12-20T17:05:12+00:00">
		2019-12-20	</time>
</div>
	</header>

	
	<div class="amp-wp-article-content">
		
		<div>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/f899ea52b67d40e1b77a0dab3ccc00ec" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="960" height="250" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/f899ea52b67d40e1b77a0dab3ccc00ec" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="960" height="250" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>Facebook人工智慧實驗室<strong>Alexander Kirillov、吳育昕、何愷明、Ross Girshick</strong>等研究人員近日發表新論文，提出一種高效、高質量的目標和場景圖像分割新方法。</p>
<p>通過將有效渲染的經典計算機圖形學方法與像素標記任務中遇到的過採樣和欠採樣問題進行類比，他們開發了一個獨特的視角，<strong>將圖像分割視為一個渲染問題</strong>。</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/adb28d2f478e4cff819eb4df026014aa" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="912" height="264" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/adb28d2f478e4cff819eb4df026014aa" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="912" height="264" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>從這個角度出發，他們提出<strong>PointRend (Point-based Rendering)神經網路模塊</strong>：該模塊基於迭代細分演算法，在自適應選擇的位置執行基於點的分割預測。</p>
<p>建立在現有的最先進的模型之上，PointRend可以靈活地應用於實例分割和語義分割任務。</p>
<p>何愷明等人的研究表明，這個簡單的設計已經取得了出色的結果。在定性上，PointRend輸出清晰的對象邊界，而先前的方法會出現過度平滑。在定量上，無論是實例分割還是語義分割，PointRend在COCO和Cityscapes兩個數據集都獲得了顯著的結果。</p>

<h2 class="pgc-h-arrow-right">PointRend：將圖像分割視作渲染問題</h2>
<p>圖像分割任務涉及將在規則網格上採樣的像素映射到同一網格上的標籤映射或一組標籤映射。在語義分割的情況下，標籤映射表示每個像素處的預測類別。在實例分割的情況下，針對每個檢測到的對象預測一個二元的前景和背景圖。用於圖像分割任務的現代工具是建立在卷積神經網路(CNN)上的。</p>
<p>用於圖像分割的CNN通常在規則網格(regular grids)上操作：輸入圖像是由像素組成的規則網格，它們的隱藏表示是規則網格上的特徵向量，它們的輸出是規則網格上的標籤映射。</p>
<p>規則網格很方便，但不一定是理想的圖像分割計算。這些網路所預測的標籤映射應該基本上是平滑的，即由於高頻區域被限制在對象之間的稀疏邊界上，因此相鄰像素常常採用相同的標籤。一個規則的網格會不必要地對平滑區域進行過採樣，同時對對象邊界進行欠採樣。結果導致在平滑區域和模糊輪廓上進行了多餘的計算(圖1，左上角)。圖像分割方法在低解析度規則網格上預測標籤，例如輸入的1/8用於語義分割，或28×28用於實例分割，作為欠採樣和過採樣之間的折衷。</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/353761ad76c140c58f35047b22b5e3e5" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="640" height="434" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/353761ad76c140c58f35047b22b5e3e5" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="640" height="434" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>圖1：PointRend的實例分割。我們引入了PointRend(基於點的渲染)模塊，該模塊使用一種新的基於點的特徵表示對圖像上的自適應採樣點進行預測。當使用PointRend替換Mask R-CNN的默認Mask head(左上)時，會產生更精細的結果(右上)。</p>
<p>類似的採樣問題在計算機圖形學中已經研究幾十年了。例如，一個渲染器將一個模型(例如，一個3D網格)映射到一個柵格化的圖像，即一個規則的像素網格。當輸出在規則網格上時，計算並不是均勻地分配到網格上的。相反，一種常見的圖形策略是計算圖像平面上自適應選擇點的不規則子集上的像素值。以Turner Whitted提出的經典subdivision技術為例，生成一個類似四叉樹的採樣模式，該模式可以有效地渲染一個抗鋸齒的高解析度圖像。</p>
<p>本研究的中心思想是<strong>將圖像分割看作一個渲染問題，並採用計算機圖形學中的經典思想來有效地「渲染」高質量的標籤圖</strong>(見圖1，左下)。我們基於這個計算思想提出一個新的神經網路模塊，稱為<strong>PointRend</strong>，它<strong>使用subdivision策略自適應地選擇一組非均勻的點來計算標籤。</strong></p>
<p>PointRend可以被合併到流行的元架構中，用於實例分割(如Mask R-CNN)和語義分割(如FCN)。它的subdivision策略使用的浮點運算比直接的密集計算要少一個數量級，從而可以有效地計算高解析度分割圖。</p>
<p>PointRend是一個<strong>通用模塊</strong>，允許多種可能的實現。從抽象的角度來看，PointRend模塊接受一個或多個定義在常規網格上的典型CNN特徵圖，並在一個更細的網格上輸出高解析度預測。與對輸出網格上的所有點進行過度預測不同，PointRend只對精心選擇的點進行預測。為了進行這些預測，它通過對f進行插值來提取所選點的點向特徵表示，並使用一個小的point head子網路來預測點向特徵的輸出標籤。</p>
<p>我們將介紹一個簡單而有效的PointRend實現。</p>
<p>我們使用COCO和Cityscapes基準來評估PointRend在實例分割和語義分割任務上的性能。定性地說，PointRend可以有效地計算出對象之間的邊界，如圖2和圖8所示。</p>
<p>我們也觀察到定量上的改進。<strong>PointRend顯著改進了Mask RCNN和DeepLabV3模型。</strong></p>

<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/0c34300859c548259406e770167aa194" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="640" height="340" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/0c34300859c548259406e770167aa194" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="640" height="340" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>圖2：使用帶標準mask head的Mask R-CNN(左)與使用帶PointRend的Mask R-CNN(右)的示例結果對比。可以看到，PointRend以更精細的細節來預測masks。</p>

<h2 class="pgc-h-arrow-right">方法：用於推理和訓練的Point Selection</h2>
<p>PointRend架構可以應用於實例分割(如Mask R-CNN)和語義分割(如FCNs)任務。對於實例分割，對每個區域應用PointRend。它通過對一組選定的點進行預測，從粗到精地計算mask(如圖3所示)。對於語義分割，可以將整個圖像視為一個區域。</p>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/8ca51d5703584a268ba1b1cd569ce3d6" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="640" height="396" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/8ca51d5703584a268ba1b1cd569ce3d6" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="640" height="396" class=""></noscript></amp-img>
<p class="pgc-img-caption">圖3：將PointRend應用於實例分割</p>

</div>
<h2 class="pgc-h-arrow-right">用於推理和訓練的Point Selection</h2>
<p>該方法的核心思想是在圖像平面中靈活、自適應地選擇點(points)來預測分割標籤。直觀上，這些點應該更密集地位於高頻區域附近，例如對象邊界，類似於光線追蹤中的抗鋸齒問題(anti-aliasing，也譯為邊緣柔化、消除混疊等)。我們推理和訓練階段應用了這一想法。</p>

<p><strong>推理：</strong></p>
<p>我們的推理選擇策略是受到計算機圖形學中經典的自適應細分技術(adaptive subdivision)的啟發。該技術被用來有效地渲染高解析度的圖像(例如，通過光線追蹤)，只計算在該值與相鄰值有顯著差異的位置；對於所有其他位置，通過對已計算的輸出值(從粗網格開始)進行插值來獲得值。</p>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/41010fcb260440aa890dc2984f8d26f2" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="950" height="294" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/41010fcb260440aa890dc2984f8d26f2" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="950" height="294" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>圖4：一個自適應細分步驟的示例。採用雙線性插值的方法對4×4網格的預測進行2×上採樣。然後，PointRend對N個最模糊的點(黑點)進行預測，以恢復更精細網格上的細節。重複此過程，直到達到所需的網格解析度。</p>
<p><strong>訓練：</strong></p>
<p>在訓練期間，PointRend還需要選擇訓練點來構造 point-wise features，以訓練point head。原則上，點的選擇策略可以類似於推理中使用的細分策略。但是， subdivision 引入了順序步驟，這對使用反向傳播訓練的神經網路不太友好。相反，對於訓練，我們使用基於隨機採樣的非迭代策略。</p>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/0af924540e164c71ad81bbf24c85469c" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="938" height="312" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/0af924540e164c71ad81bbf24c85469c" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="938" height="312" class=""></noscript></amp-img>
<p class="pgc-img-caption">圖5：訓練期間的點採樣</p>

</div>
<p>實驗和結果：實例分割和語義分割均優於基線方法</p>
<h2 class="pgc-h-arrow-right">實例分割</h2>
<p>我們將PointRend與表1中Mask R-CNN中默認的4×conv head進行比較。</p>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/2abb1d70985b44049d463ee7d9c4f116" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="920" height="244" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/2abb1d70985b44049d463ee7d9c4f116" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="920" height="244" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>表1：PointRend與Mask R-CNN的默認4×conv mask head的對比。PointRend在數量和質量上都優於標準的4×conv mask head。</p>
<p>PointRend在兩個數據集上的性能都優於默認的head。即使輸出解析度相同，PointRend的性能也優於baseline。從直觀上看，邊界質量也差異明顯，如圖6所示。</p>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/e0eeefc4541449478e9b17d706d25639" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="640" height="341" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/e0eeefc4541449478e9b17d706d25639" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="640" height="341" class=""></noscript></amp-img>
<p class="pgc-img-caption">圖6:具有不同輸出解析度的PointRend推理。高解析度 masks 與對象邊界更好地對齊了。</p>

</div>
<p>細分推理允許PointRend產生高解析度的224×224預測，使用的計算(FLOPs)和內存是默認的4×conv head輸出相同解析度所需的30倍以上，見表2。</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/7d2e094c6b754d82b6ccbc92943b76a0" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="726" height="176" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/7d2e094c6b754d82b6ccbc92943b76a0" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="726" height="176" class=""></noscript></amp-img>
<p class="pgc-img-caption">表2：224×224輸出解析度mask的FLOP（multiply-adds）和激活計數。</p>

</div>
<p>PointRend通過忽略一個對象的某些區域(例如，遠離對象邊界的區域)來實現Mask R-CNN框架下的高解析度輸出。</p>
<p>表3顯示了不同輸出解析度和在每個細分步驟中選擇的點數的PointRend細分推斷。以更高的解析度預測掩模可以改進結果。雖然AP飽和，但從較低(如56×56)解析度輸出到較高(如224×224)解析度輸出時，視覺效果仍有明顯改善，見圖7。</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/66e9e3ad206a43a583cd8412c5b0c34d" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="640" height="316" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/66e9e3ad206a43a583cd8412c5b0c34d" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="640" height="316" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>表3：細分推理參數。更高的輸出解析度提高了AP。雖然隨著每個細分步驟中採樣點的數量的增加，改進會很快達到飽和(在下劃線處的值)，但對於複雜的對象，定性結果可能會繼續改進。</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/5985e0b906dd44388853dabedddee510" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="640" height="405" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/5985e0b906dd44388853dabedddee510" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="640" height="405" class=""></noscript></amp-img>
<p class="pgc-img-caption">圖7：使用PointRend進行抗鋸齒</p>

</div>
<p><strong>語義分割</strong></p>
<p><strong>DeeplabV3。</strong>在表6中，我們將DeepLabV3與帶有PointRend的DeepLabV3進行了比較。通過使用res4階段的擴展卷積，推理階段輸出解析度也可以提高2倍。相比兩者，PointRend具有更高的mIoU。定性改進也很明顯，見圖8。</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/3bffe75c750f4049bbb6f6928688fb85" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="1020" height="230" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/3bffe75c750f4049bbb6f6928688fb85" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="1020" height="230" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>表6：在Cityscapes數據集，帶有PointRend的DeeplabV3語義分割的性能優於基線DeepLabV3。在推理過程中對res4階段進行擴展會產生更大，更準確的預測，但計算和存儲成本要高得多。仍然不如使用PointRend。</p>
<div class="pgc-img">
  <amp-img src="http://p9.pstatp.com/large/pgc-image/194d76dfcbf84e43a5b2c160ac64198d" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="1080" height="306" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p9.pstatp.com/large/pgc-image/194d76dfcbf84e43a5b2c160ac64198d" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="1080" height="306" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>圖8：Cityscapes上的實例分割和語義分割結果。在實例分割中，較大的對象更容易從PointRend能力中獲得高解析度的輸出。而在語義分割方面，PointRend可以恢復小的對象和細節。</p>
<p>通過自適應採樣點，僅對32k點進行預測， PointRend可以達到1024×2048解析度(即2M點)，如圖9所示。</p>
<div class="pgc-img">
  <amp-img src="http://p9.pstatp.com/large/pgc-image/7de6dcce5fcc4939aa6b3b4ab0be2b80" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="640" height="255" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p9.pstatp.com/large/pgc-image/7de6dcce5fcc4939aa6b3b4ab0be2b80" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="640" height="255" class=""></noscript></amp-img>
<p class="pgc-img-caption">圖9：語義分割的PointRend推斷。</p>

</div>
<p>SemanticFPN。表7顯示，具有PointRend的SemanticFPN優於沒有PointRend的8×和4×輸出步長變體。</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/754f25f80069468e8fe1825d413795db" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="1080" height="267" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/754f25f80069468e8fe1825d413795db" alt="《何愷明團隊又出神作：將圖像分割視作渲染問題，性能顯著提升》" width="1080" height="267" class=""></noscript></amp-img>
<p class="pgc-img-caption">Cityscapes中，帶有PointRend的SemanticFPN語義分割性能優於基線SemanticFPN</p>

</div>
<p>*內容及圖片來源於網路，侵權請聯繫小編。</p>
</div>
	</div>

	<footer class="amp-wp-article-footer">
			<div class="amp-wp-meta amp-wp-tax-category">
		分類: <a href="https://daynews.cc/technology/" rel="category tag">科技</a>	</div>

		<div class="amp-wp-meta amp-wp-comments-link">
		<a href="https://daynews.cc/technology/26921/#comments">
			寫評論		</a>
	</div>
	</footer>
</article>

<footer class="amp-wp-footer">
	<div>
		<h2>天天要聞</h2>
		<a href="#top" class="back-to-top">返回頂部</a>
	</div>
</footer>


<amp-analytics id="354f0d2beeef" type="baiduanalytics"><script type="application/json">{"vars":{"token":"882f12dcdadf8f87fabf76b550649115"},"triggers":{"trackPageview":{"on":"visible","request":"pageview"}}}</script></amp-analytics>
</body>
</html>
<!-- This is the static html file -->