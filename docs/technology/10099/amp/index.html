<!doctype html>
<html amp lang="zh-TW">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
	<script type='application/ld+json' class='yoast-schema-graph yoast-schema-graph--main'>{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://daynews.cc/#website","url":"https://daynews.cc/","name":"\u5929\u5929\u8981\u805e","description":"\u4e00\u7db2\u6253\u76e1\u5168\u7db2\u6700\u65b0\u8cc7\u8a0a\u6700\u71b1\u982d\u689d\u65b0","potentialAction":{"@type":"SearchAction","target":"https://daynews.cc/?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://daynews.cc/technology/10099#primaryimage","url":"http://p3.pstatp.com/large/pgc-image/e748a56aef4a479497668dd28204e0dc"},{"@type":"WebPage","@id":"https://daynews.cc/technology/10099#webpage","url":"https://daynews.cc/technology/10099","inLanguage":"zh-TW","name":"\u6df1\u5ea6\u5b78\u7fd2\u4e2d\u7684\u76ee\u6a19\u6aa2\u6e2c\u662f\u4ec0\u9ebc\uff1f\u6709\u54ea\u4e9b\u6f14\u7b97\u6cd5\u548c\u95dc\u9375\u9ede - \u5929\u5929\u8981\u805e","isPartOf":{"@id":"https://daynews.cc/#website"},"primaryImageOfPage":{"@id":"https://daynews.cc/technology/10099#primaryimage"},"datePublished":"2019-12-07T02:50:16+00:00","dateModified":"2019-12-07T02:50:16+00:00","author":{"@id":"https://daynews.cc/#/schema/person/038ceb5ed68cf11f9ec94ba43c7ff55d"}},{"@type":["Person"],"@id":"https://daynews.cc/#/schema/person/038ceb5ed68cf11f9ec94ba43c7ff55d","name":"\u5929\u5929\u8981\u805e","image":{"@type":"ImageObject","@id":"https://daynews.cc/#authorlogo","url":"https://secure.gravatar.com/avatar/e786821a74ef0467825a7d60183307bc?s=96&d=mm&r=g","caption":"\u5929\u5929\u8981\u805e"},"sameAs":[]}]}</script>
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:description" content="Object Detection，就是在給定的圖片中精確找到物體所在位置，並標註出物體的類別。所以，object detection要解決的問題就是物體在哪裡以及是什麼的整個流程問題。 然而，這個問題可不是那麼容易解決的，物體的尺寸變化範圍很大，擺放物體的角度，姿態不定，而且可以出現在圖片的任何地方，更何況物體還可以是多個類別。 目前學術……" />
<meta name="twitter:title" content="深度學習中的目標檢測是什麼？有哪些演算法和關鍵點 - 天天要聞" />
<meta name="twitter:image" content="http://p3.pstatp.com/large/pgc-image/e748a56aef4a479497668dd28204e0dc" />
<meta property="og:locale" content="zh_TW" />
<meta property="og:type" content="article" />
<meta property="og:title" content="深度學習中的目標檢測是什麼？有哪些演算法和關鍵點 - 天天要聞" />
<meta property="og:description" content="Object Detection，就是在給定的圖片中精確找到物體所在位置，並標註出物體的類別。所以，object detection要解決的問題就是物體在哪裡以及是什麼的整個流程問題。 然而，這個問題可不是那麼容易解決的，物體的尺寸變化範圍很大，擺放物體的角度，姿態不定，而且可以出現在圖片的任何地方，更何況物體還可以是多個類別。 目前學術……" />
<meta property="og:url" content="https://daynews.cc/technology/10099" />
<meta property="og:site_name" content="天天要聞" />
<meta property="article:section" content="科技" />
<meta property="article:published_time" content="2019-12-07T02:50:16+00:00" />
	<title>深度學習中的目標檢測是什麼？有哪些演算法和關鍵點 - 天天要聞</title>
		<link rel="canonical" href="https://daynews.cc/technology/10099" />
	<script type='text/javascript' src='https://cdn.ampproject.org/v0.js' async></script>
<script type='text/javascript' src='https://cdn.ampproject.org/v0/amp-analytics-0.1.js' async custom-element="amp-analytics"></script>
<style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript><meta name="generator" content="AMP Plugin v1.4.1; mode=reader; experiences=website"><meta name="generator" content="WordPress 5.2.4" />
	<style amp-custom>
		/* Generic WP styling */

.alignright {
	float: right;
}

.alignleft {
	float: left;
}

.aligncenter {
	display: block;
	text-align: center;
	margin-left: auto;
	margin-right: auto;
}

.amp-wp-enforced-sizes {
	/** Our sizes fallback is 100vw, and we have a padding on the container; the max-width here prevents the element from overflowing. **/
	max-width: 100%;
	margin: 0 auto;
}


/*
 * Prevent cases of amp-img converted from img to appear with stretching by using object-fit to scale.
 * See <https://github.com/ampproject/amphtml/issues/21371#issuecomment-475443219>.
 * Also use object-fit:contain in worst case scenario when we can't figure out dimensions for an image.
 * Additionally, in side of \AMP_Img_Sanitizer::determine_dimensions() it could $amp_img->setAttribute( 'object-fit', 'contain' )
 * so that the following rules wouldn't be needed.
 */
amp-img.amp-wp-enforced-sizes[layout="intrinsic"] > img,
amp-anim.amp-wp-enforced-sizes[layout="intrinsic"] > img {
	object-fit: contain;
}

amp-fit-text blockquote,
amp-fit-text h1,
amp-fit-text h2,
amp-fit-text h3,
amp-fit-text h4,
amp-fit-text h5,
amp-fit-text h6 {
	font-size: inherit;
}

/**
 * Override a style rule in Twenty Sixteen and Twenty Seventeen.
 * It set display:none for audio elements.
 * This selector is the same, though it adds body and uses amp-audio instead of audio.
 */
body amp-audio:not([controls]) {
	display: inline-block;
	height: auto;
}

/*
 * Style the default template messages for submit-success, submit-error, and submitting. These elements are inserted
 * by the form sanitizer when a POST form lacks the action-xhr attribute.
 */
.amp-wp-default-form-message > p {
	margin: 1em 0;
	padding: 0.5em;
}

.amp-wp-default-form-message[submitting] > p,
.amp-wp-default-form-message[submit-success] > p.amp-wp-form-redirecting {
	font-style: italic;
}

.amp-wp-default-form-message[submit-success] > p:not(.amp-wp-form-redirecting) {
	border: solid 1px #008000;
	background-color: #90ee90;
	color: #000;
}

.amp-wp-default-form-message[submit-error] > p {
	border: solid 1px #f00;
	background-color: #ffb6c1;
	color: #000;
}

/* Prevent showing empty success message in the case of an AMP-Redirect-To response header. */
.amp-wp-default-form-message[submit-success] > p:empty {
	display: none;
}

amp-carousel .amp-wp-gallery-caption {
	position: absolute;
	bottom: 0;
	left: 0;
	right: 0;
	text-align: center;
	background-color: rgba(0, 0, 0, 0.5);
	color: #fff;
	padding: 1rem;
}

.wp-block-gallery[data-amp-carousel="true"] {
	display: block;
	flex-wrap: unset;
}

/* Template Styles */

.amp-wp-content,
.amp-wp-title-bar div {
		margin: 0 auto;
	max-width: 600px;
	}

html {
	background: #0a89c0;
}

body {
	background: #fff;
	color: #353535;
	font-family: Georgia, 'Times New Roman', Times, Serif;
	font-weight: 300;
	line-height: 1.75em;
}

p,
ol,
ul,
figure {
	margin: 0 0 1em;
	padding: 0;
}

a,
a:visited {
	color: #0a89c0;
}

a:hover,
a:active,
a:focus {
	color: #353535;
}

/* Quotes */

blockquote {
	color: #353535;
	background: rgba(127,127,127,.125);
	border-left: 2px solid #0a89c0;
	margin: 8px 0 24px 0;
	padding: 16px;
}

blockquote p:last-child {
	margin-bottom: 0;
}

/* UI Fonts */

.amp-wp-meta,
.amp-wp-header div,
.amp-wp-title,
.wp-caption-text,
.amp-wp-tax-category,
.amp-wp-tax-tag,
.amp-wp-comments-link,
.amp-wp-footer p,
.back-to-top {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen-Sans", "Ubuntu", "Cantarell", "Helvetica Neue", sans-serif;
}

/* Header */

.amp-wp-header {
	background-color: #0a89c0;
}

.amp-wp-header div {
	color: #fff;
	font-size: 1em;
	font-weight: 400;
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: .875em 16px;
	position: relative;
}

.amp-wp-header a {
	color: #fff;
	text-decoration: none;
}


.amp-wp-header .amp-wp-site-icon {
	/** site icon is 32px **/
	background-color: #fff;
	border: 1px solid #fff;
	border-radius: 50%;
	position: absolute;
	right: 18px;
	top: 10px;
}

/* Article */

.amp-wp-article {
	color: #353535;
	font-weight: 400;
	margin: 1.5em auto;
	max-width: 840px;
	overflow-wrap: break-word;
	word-wrap: break-word;
}

/* Article Header */

.amp-wp-article-header {
	align-items: center;
	align-content: stretch;
	display: flex;
	flex-wrap: wrap;
	justify-content: space-between;
	margin: 1.5em 16px 0;
}

.amp-wp-title {
	color: #353535;
	display: block;
	flex: 1 0 100%;
	font-weight: 900;
	margin: 0 0 .625em;
	width: 100%;
}

/* Article Meta */

.amp-wp-meta {
	color: #696969;
	display: inline-block;
	flex: 2 1 50%;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0 0 1.5em;
	padding: 0;
}

.amp-wp-article-header .amp-wp-meta:last-of-type {
	text-align: right;
}

.amp-wp-article-header .amp-wp-meta:first-of-type {
	text-align: left;
}

.amp-wp-byline amp-img,
.amp-wp-byline .amp-wp-author {
	display: inline-block;
	vertical-align: middle;
}

.amp-wp-byline amp-img {
	border: 1px solid #0a89c0;
	border-radius: 50%;
	position: relative;
	margin-right: 6px;
}

.amp-wp-posted-on {
	text-align: right;
}

/* Featured image */

.amp-wp-article-featured-image {
	margin: 0 0 1em;
}
.amp-wp-article-featured-image amp-img {
	margin: 0 auto;
}
.amp-wp-article-featured-image.wp-caption .wp-caption-text {
	margin: 0 18px;
}

/* Article Content */

.amp-wp-article-content {
	margin: 0 16px;
}

.amp-wp-article-content ul,
.amp-wp-article-content ol {
	margin-left: 1em;
}

.amp-wp-article-content .wp-caption {
	max-width: 100%;
}

.amp-wp-article-content amp-img {
	margin: 0 auto;
}

.amp-wp-article-content amp-img.alignright {
	margin: 0 0 1em 16px;
}

.amp-wp-article-content amp-img.alignleft {
	margin: 0 16px 1em 0;
}

/* Captions */

.wp-caption {
	padding: 0;
}

.wp-caption.alignleft {
	margin-right: 16px;
}

.wp-caption.alignright {
	margin-left: 16px;
}

.wp-caption .wp-caption-text {
	border-bottom: 1px solid #c2c2c2;
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0;
	padding: .66em 10px .75em;
}

/* AMP Media */

.alignwide,
.alignfull {
	clear: both;
}

amp-carousel {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}
amp-iframe,
amp-youtube,
amp-instagram,
amp-vine {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}

.amp-wp-article-content amp-carousel amp-img {
	border: none;
}

amp-carousel > amp-img > img {
	object-fit: contain;
}

.amp-wp-iframe-placeholder {
	background: #c2c2c2 url( https://daynews.cc/wp-content/plugins/amp/assets/images/placeholder-icon.png ) no-repeat center 40%;
	background-size: 48px 48px;
	min-height: 48px;
}

/* Article Footer Meta */

.amp-wp-article-footer .amp-wp-meta {
	display: block;
}

.amp-wp-tax-category,
.amp-wp-tax-tag {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 1.5em 16px;
}

.amp-wp-comments-link {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	text-align: center;
	margin: 2.25em 0 1.5em;
}

.amp-wp-comments-link a {
	border-style: solid;
	border-color: #c2c2c2;
	border-width: 1px 1px 2px;
	border-radius: 4px;
	background-color: transparent;
	color: #0a89c0;
	cursor: pointer;
	display: block;
	font-size: 14px;
	font-weight: 600;
	line-height: 18px;
	margin: 0 auto;
	max-width: 200px;
	padding: 11px 16px;
	text-decoration: none;
	width: 50%;
	-webkit-transition: background-color 0.2s ease;
			transition: background-color 0.2s ease;
}

/* AMP Footer */

.amp-wp-footer {
	border-top: 1px solid #c2c2c2;
	margin: calc(1.5em - 1px) 0 0;
}

.amp-wp-footer div {
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: 1.25em 16px 1.25em;
	position: relative;
}

.amp-wp-footer h2 {
	font-size: 1em;
	line-height: 1.375em;
	margin: 0 0 .5em;
}

.amp-wp-footer p {
	color: #696969;
	font-size: .8em;
	line-height: 1.5em;
	margin: 0 85px 0 0;
}

.amp-wp-footer a {
	text-decoration: none;
}

.back-to-top {
	bottom: 1.275em;
	font-size: .8em;
	font-weight: 600;
	line-height: 2em;
	position: absolute;
	right: 16px;
}
		td, th {
	text-align: left;
}

a, a:active, a:visited {
	text-decoration: underline;
}

	</style>
</head>

<body class="">

<header id="top" class="amp-wp-header">
	<div>
		<a href="https://daynews.cc/">
									<span class="amp-site-title">
				天天要聞			</span>
		</a>

					</div>
</header>

<article class="amp-wp-article">
	<header class="amp-wp-article-header">
		<h1 class="amp-wp-title">深度學習中的目標檢測是什麼？有哪些演算法和關鍵點</h1>
			<div class="amp-wp-meta amp-wp-byline">
					<amp-img src="https://secure.gravatar.com/avatar/e786821a74ef0467825a7d60183307bc?s=24&#038;d=mm&#038;r=g" alt="天天要聞" width="24" height="24" layout="fixed"></amp-img>
				<span class="amp-wp-author author vcard">天天要聞</span>
	</div>
<div class="amp-wp-meta amp-wp-posted-on">
	<time datetime="2019-12-07T10:50:16+00:00">
		2 週 ago	</time>
</div>
	</header>

	
	<div class="amp-wp-article-content">
		<div>
<blockquote>
<p><strong>Object Detection，就是在給定的圖片中精確找到物體所在位置，並標註出物體的類別。所以，object detection要解決的問題就是物體在哪裡以及是什麼的整個流程問題。</strong></p>
</blockquote>
<p>然而，這個問題可不是那麼容易解決的，物體的尺寸變化範圍很大，擺放物體的角度，姿態不定，而且可以出現在圖片的任何地方，更何況物體還可以是多個類別。</p>
<h2>目前學術和工業界出現的目標檢測演算法分成3類：</h2>
<p><strong>1. 傳統的目標檢測演算法</strong>：Cascade + HOG/DPM + Haar/SVM以及上述方法的諸多改進、優化；</p>
<p><strong>2. 候選區域/框 + 深度學習分類</strong>：通過提取候選區域，並對相應區域進行以深度學習方法為主的分類的方案，如：</p>
<ul class="">
<li>R-CNN（Selective Search + CNN + SVM）</li>
</ul>
<ul class="">
<li>SPP-net（ROI Pooling）</li>
</ul>
<ul class="">
<li>Fast R-CNN（Selective Search + CNN + ROI）</li>
</ul>
<ul class="">
<li>Faster R-CNN（RPN + CNN + ROI）</li>
</ul>
<ul class="">
<li>R-FCN</li>
</ul>
<p>等系列方法；</p>
<p><strong>3. 基於深度學習的回歸方法</strong>：YOLO/SSD/DenseBox 等方法；以及最近出現的結合RNN演算法的RRC detection；結合DPM的Deformable CNN等</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/e748a56aef4a479497668dd28204e0dc" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="369" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/e748a56aef4a479497668dd28204e0dc" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="369" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<h2>傳統目標檢測流程：</h2>
<p><strong>1）區域選擇（</strong>窮舉策略：採用滑動窗口，且設置不同的大小，不同的長寬比對圖像進行遍歷，時間複雜度高）</p>
<p><strong>2）特徵提取</strong>（SIFT、HOG等；形態多樣性、光照變化多樣性、背景多樣性使得特徵魯棒性差）</p>
<p><strong>3）分類器分類</strong>（主要有SVM、Adaboost等）</p>
<h2><strong>二、傳統的目標檢測演算法</strong></h2>
<h2><strong>2.1 從圖像識別的任務說起</strong></h2>
<p>這裡有一個圖像任務：既要把圖中的物體識別出來，又要用方框框出它的位置。</p>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/71eb71ee39264f0bbfeb9ccb0bd23eea" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="297" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/71eb71ee39264f0bbfeb9ccb0bd23eea" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="297" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>這個任務本質上就是這兩個問題：</p>
<ul class="">
<li>一：圖像識別</li>
<li>二：定位</li>
</ul>
<p>圖像識別（classification）：</p>
<ul class="">
<li>輸入：圖片</li>
</ul>
<ul class="">
<li>輸出：物體的類別</li>
</ul>
<ul class="">
<li>評估方法：準確率</li>
</ul>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/06feb6a06a7e4798be2fdb4a1043b20c" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="379" height="151" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/06feb6a06a7e4798be2fdb4a1043b20c" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="379" height="151" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>定位（localization）：</p>
<ul class="">
<li>輸入：圖片</li>
</ul>
<ul class="">
<li>輸出：方框在圖片中的位置（x,y,w,h）</li>
</ul>
<ul class="">
<li>評估方法：檢測評價函數intersection-over-union（關於什麼是IOU，請參看本深度學習分類下第55題：https://www.julyedu.com/question/big/kp_id/26/ques_id/2138）</li>
</ul>
<div class="pgc-img">
  <amp-img src="http://p9.pstatp.com/large/pgc-image/6fdbcd4f4c0049da832a1889cf176562" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="416" height="221" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p9.pstatp.com/large/pgc-image/6fdbcd4f4c0049da832a1889cf176562" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="416" height="221" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>卷積神經網路CNN已經幫我們完成了圖像識別（判定是貓還是狗）的任務了，我們只需要添加一些額外的功能來完成定位任務即可。</p>
<h2>定位的問題的解決思路有哪些？</h2>
<p><strong>思路一：看做回歸問題</strong></p>
<p>看做回歸問題，我們需要預測出（x,y,w,h）四個參數的值，從而得出方框的位置。</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/ac31d7106cee4cc58e6287459053fe4d" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="284" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/ac31d7106cee4cc58e6287459053fe4d" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="284" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p><strong>步驟1:</strong></p>
<p>*先解決簡單問題， 搭一個識別圖像的神經網路</p>
<p>*在AlexNet VGG GoogleLenet上fine-tuning一下（關於什麼是微調fine-tuning，請參看本深度學習分類下第54題：https://www.julyedu.com/question/big/kp_id/26/ques_id/2137）</p>

<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/43269257913b4144a39e6c6b3562cca3" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="948" height="309" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/43269257913b4144a39e6c6b3562cca3" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="948" height="309" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p><strong>步驟2:</strong></p>
<p>*在上述神經網路的尾部展開（也就說CNN前面保持不變，我們對CNN的結尾處作出改進：加了兩個頭：「分類頭」和「回歸頭」）</p>
<p>*成為classification + regression模式</p>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/7998ed85f5684d78b03d9e7020f5c149" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="246" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/7998ed85f5684d78b03d9e7020f5c149" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="246" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p><strong>步驟3:</strong></p>
<p>*Regression那個部分用歐氏距離損失</p>
<p>*使用SGD訓練</p>
<p><strong>步驟4:</strong></p>
<p>*預測階段把2個頭部拼上</p>
<p>*完成不同的功能</p>
<p>這裡需要進行兩次fine-tuning</p>
<p>第一次在ALexNet上做，第二次將頭部改成regression head，前面不變，做一次fine-tuning</p>
<p><strong>Regression的部分加在哪？</strong></p>
<p>有兩種處理方法：</p>
<p>　　•加在最後一個卷積層後面（如VGG）</p>
<p>　　•加在最後一個全連接層後面（如R-CNN）</p>
<p>regression太難做了，應想方設法轉換為classification問題。</p>
<p>regression的訓練參數收斂的時間要長得多，所以上面的網路採取了用classification的網路來計算出網路共同部分的連接權值。</p>
<p><strong>思路二：取圖像窗口</strong></p>
<p>　　•還是剛才的classification + regression思路</p>
<p>　　•咱們取不同的大小的「框」</p>
<p>　　•讓框出現在不同的位置，得出這個框的判定得分</p>
<p>　　•取得分最高的那個框</p>
<p>左上角的黑框：得分0.5</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/9e163563e19b4a07b1c9b17b59fb6c0e" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="293" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/9e163563e19b4a07b1c9b17b59fb6c0e" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="293" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>右上角的黑框：得分0.75</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/92b860ab5899406f92dc80721b588d3b" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="276" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/92b860ab5899406f92dc80721b588d3b" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="276" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>左下角的黑框：得分0.6</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/8c77cb28141c4d8d952ee205bce9032f" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="275" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/8c77cb28141c4d8d952ee205bce9032f" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="275" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>右下角的黑框：得分0.8</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/9bad8027e995491ab4817022fbf74bd6" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="280" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/9bad8027e995491ab4817022fbf74bd6" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="280" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>根據得分的高低，我們選擇了右下角的黑框作為目標位置的預測。</p>
<p><strong>註：</strong>有的時候也會選擇得分最高的兩個框，然後取兩框的交集作為最終的位置預測。</p>
<p>疑惑：框要取多大？</p>
<p>取不同的框，依次從左上角掃到右下角。非常粗暴啊。</p>
<h2><strong>總結一下思路：</strong></h2>
<p>對一張圖片，用各種大小的框（遍歷整張圖片）將圖片截取出來，輸入到CNN，然後CNN會輸出這個框的得分（classification）以及這個框圖片對應的x,y,h,w（regression）。</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/5be595f537744e8cacf1d4178f7183fc" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="956" height="271" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/5be595f537744e8cacf1d4178f7183fc" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="956" height="271" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>這方法實在太耗時間了，做個優化。</p>
<p>原來網路是這樣的：</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/9f3c19a67c014bc2815a6f8d819717af" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="321" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/9f3c19a67c014bc2815a6f8d819717af" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="321" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>優化成這樣：把全連接層改為卷積層，這樣可以提提速。</p>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/7e9eaa70eaa347f09fc042dbcf38f3fc" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="240" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/7e9eaa70eaa347f09fc042dbcf38f3fc" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="640" height="240" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<h2><strong>2.2 物體檢測（Object Detection）</strong></h2>
<p>當圖像有很多物體怎麼辦的？難度可是一下暴增啊。</p>
<p>那任務就變成了：<strong>多物體識別+定位多個物體</strong></p>
<p>那把這個任務看做分類問題？</p>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/e799bdfa934a48a3a619608145b8b0e6" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="473" height="315" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/e799bdfa934a48a3a619608145b8b0e6" alt="《深度學習中的目標檢測是什麼？有哪些演算法和關鍵點》" width="473" height="315" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>看成分類問題有何不妥？</p>
<p>　　•你需要找很多位置， 給很多個不同大小的框</p>
<p>　　•你還需要對框內的圖像分類</p>
<p>　　•當然， 如果你的GPU很強大， 恩， 那加油做吧…</p>
<p>所以，<strong>傳統目標檢測的主要問題</strong>是：</p>
<p>1）基於滑動窗口的區域選擇策略沒有針對性，時間複雜度高，窗口冗餘</p>
<p>2）手工設計的特徵對於多樣性的變化沒有很好的魯棒性</p>
<p>看做classification， 有沒有辦法優化下？我可不想試那麼多框那麼多位置啊！</p>
<h2>下節預告：</h2>
<blockquote>
<p>下節將對R-CNN、Fast R-CNN、Faster R-CNN、YOLO、SSD目標檢測網路一一講述，歡迎持續關注哦</p>
</blockquote>
<p><strong>往期回顧</strong>：<a class="pgc-link" data-content="mp" href="https://www.toutiao.com/i6766579765039071755/?group_id=6766579765039071755" target="_blank">Python數據系列（一）- 列表List：Python的「苦力」</a></p>
<p><a class="pgc-link" data-content="mp" href="https://www.toutiao.com/i6766923131148829196/?group_id=6766923131148829196" target="_blank">Python數據系列（二）- 字典Dictionary：Python的「大胃王」</a></p>
<p><a class="pgc-link" data-content="mp" href="https://www.toutiao.com/i6766223050292593156/?group_id=6766223050292593156" target="_blank">深度學習在計算機視覺圖像分割演算法中，批量圖像數據增強的方法</a></p>
</div>
	</div>

	<footer class="amp-wp-article-footer">
			<div class="amp-wp-meta amp-wp-tax-category">
		Categories: <a href="https://daynews.cc/technology" rel="category tag">科技</a>	</div>

		<div class="amp-wp-meta amp-wp-comments-link">
		<a href="https://daynews.cc/technology/10099#comments">
			Leave a Comment		</a>
	</div>
	</footer>
</article>

<footer class="amp-wp-footer">
	<div>
		<h2>天天要聞</h2>
		<a href="#top" class="back-to-top">Back to top</a>
	</div>
</footer>


<amp-analytics id="4c2faa84438c" type="gtag"><script type="application/json">{"vars":{"gtag_id":"UA-154709495-1","config":{"UA-154709495-1":{"groups":"default"}}}}</script></amp-analytics>
</body>
</html>

<!-- Dynamic page generated in 0.256 seconds. -->
<!-- Cached page generated by WP-Super-Cache on 2019-12-18 14:10:50 -->

<!-- super cache -->