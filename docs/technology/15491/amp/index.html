<!doctype html>
<html amp lang="zh-TW">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
	<script type='application/ld+json' class='yoast-schema-graph yoast-schema-graph--main'>{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://daynews.cc/#website","url":"https://daynews.cc/","name":"\u5929\u5929\u8981\u805e","description":"\u4e00\u7db2\u6253\u76e1\u5168\u7db2\u6700\u65b0\u8cc7\u8a0a\u6700\u71b1\u982d\u689d\u65b0","potentialAction":{"@type":"SearchAction","target":"https://daynews.cc/?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://daynews.cc/technology/15491/#primaryimage","url":"http://p9.pstatp.com/large/pgc-image/cbbe8da2aaed4c2083f5c43dc0c5a770"},{"@type":"WebPage","@id":"https://daynews.cc/technology/15491/#webpage","url":"https://daynews.cc/technology/15491/","inLanguage":"zh-TW","name":"\u6a5f\u5668\u5b78\u7fd2\uff1aAutoGluon\u4ecb\u7d39\u53ca\u793a\u4f8b - \u5929\u5929\u8981\u805e","isPartOf":{"@id":"https://daynews.cc/#website"},"primaryImageOfPage":{"@id":"https://daynews.cc/technology/15491/#primaryimage"},"datePublished":"2019-12-14T10:50:09+00:00","dateModified":"2019-12-14T10:50:09+00:00","author":{"@id":"https://daynews.cc/#/schema/person/038ceb5ed68cf11f9ec94ba43c7ff55d"}},{"@type":["Person"],"@id":"https://daynews.cc/#/schema/person/038ceb5ed68cf11f9ec94ba43c7ff55d","name":"\u5929\u5929\u8981\u805e","image":{"@type":"ImageObject","@id":"https://daynews.cc/#authorlogo","url":"https://secure.gravatar.com/avatar/e786821a74ef0467825a7d60183307bc?s=96&d=mm&r=g","caption":"\u5929\u5929\u8981\u805e"},"sameAs":[]}]}</script>
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:description" content="介紹AutoGluon AutoGluon是一個新的開源 AutoML庫，可針對涉及圖像，文本和表格數據集的實際應用，自動進行深度學習（DL）和機器學習（ML）。無論您是機器學習新手還是經驗豐富的從業人員，AutoGluon都能簡化您的工作流程。使用AutoGluon，您可以僅使用幾行Python代碼來開發和完善深度學習模型。 主要特點 ……" />
<meta name="twitter:title" content="機器學習：AutoGluon介紹及示例 - 天天要聞" />
<meta name="twitter:image" content="http://p9.pstatp.com/large/pgc-image/cbbe8da2aaed4c2083f5c43dc0c5a770" />
<meta property="og:locale" content="zh_TW" />
<meta property="og:type" content="article" />
<meta property="og:title" content="機器學習：AutoGluon介紹及示例 - 天天要聞" />
<meta property="og:description" content="介紹AutoGluon AutoGluon是一個新的開源 AutoML庫，可針對涉及圖像，文本和表格數據集的實際應用，自動進行深度學習（DL）和機器學習（ML）。無論您是機器學習新手還是經驗豐富的從業人員，AutoGluon都能簡化您的工作流程。使用AutoGluon，您可以僅使用幾行Python代碼來開發和完善深度學習模型。 主要特點 ……" />
<meta property="og:url" content="https://daynews.cc/technology/15491/" />
<meta property="og:site_name" content="天天要聞" />
<meta property="article:section" content="科技" />
<meta property="article:published_time" content="2019-12-14T10:50:09+00:00" />
	<title>機器學習：AutoGluon介紹及示例 - 天天要聞</title>
		<link rel="canonical" href="https://daynews.cc/technology/15491/" />
	<script type='text/javascript' src='https://cdn.ampproject.org/v0.js' async></script>
<script type='text/javascript' src='https://cdn.ampproject.org/v0/amp-analytics-0.1.js' async custom-element="amp-analytics"></script>
<style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript><meta name="generator" content="AMP Plugin v1.4.1; mode=reader; experiences=website"><meta name="generator" content="WordPress 5.2.4" />
	<style amp-custom>
		/* Generic WP styling */

.alignright {
	float: right;
}

.alignleft {
	float: left;
}

.aligncenter {
	display: block;
	text-align: center;
	margin-left: auto;
	margin-right: auto;
}

.amp-wp-enforced-sizes {
	/** Our sizes fallback is 100vw, and we have a padding on the container; the max-width here prevents the element from overflowing. **/
	max-width: 100%;
	margin: 0 auto;
}


/*
 * Prevent cases of amp-img converted from img to appear with stretching by using object-fit to scale.
 * See <https://github.com/ampproject/amphtml/issues/21371#issuecomment-475443219>.
 * Also use object-fit:contain in worst case scenario when we can't figure out dimensions for an image.
 * Additionally, in side of \AMP_Img_Sanitizer::determine_dimensions() it could $amp_img->setAttribute( 'object-fit', 'contain' )
 * so that the following rules wouldn't be needed.
 */
amp-img.amp-wp-enforced-sizes[layout="intrinsic"] > img,
amp-anim.amp-wp-enforced-sizes[layout="intrinsic"] > img {
	object-fit: contain;
}

amp-fit-text blockquote,
amp-fit-text h1,
amp-fit-text h2,
amp-fit-text h3,
amp-fit-text h4,
amp-fit-text h5,
amp-fit-text h6 {
	font-size: inherit;
}

/**
 * Override a style rule in Twenty Sixteen and Twenty Seventeen.
 * It set display:none for audio elements.
 * This selector is the same, though it adds body and uses amp-audio instead of audio.
 */
body amp-audio:not([controls]) {
	display: inline-block;
	height: auto;
}

/*
 * Style the default template messages for submit-success, submit-error, and submitting. These elements are inserted
 * by the form sanitizer when a POST form lacks the action-xhr attribute.
 */
.amp-wp-default-form-message > p {
	margin: 1em 0;
	padding: 0.5em;
}

.amp-wp-default-form-message[submitting] > p,
.amp-wp-default-form-message[submit-success] > p.amp-wp-form-redirecting {
	font-style: italic;
}

.amp-wp-default-form-message[submit-success] > p:not(.amp-wp-form-redirecting) {
	border: solid 1px #008000;
	background-color: #90ee90;
	color: #000;
}

.amp-wp-default-form-message[submit-error] > p {
	border: solid 1px #f00;
	background-color: #ffb6c1;
	color: #000;
}

/* Prevent showing empty success message in the case of an AMP-Redirect-To response header. */
.amp-wp-default-form-message[submit-success] > p:empty {
	display: none;
}

amp-carousel .amp-wp-gallery-caption {
	position: absolute;
	bottom: 0;
	left: 0;
	right: 0;
	text-align: center;
	background-color: rgba(0, 0, 0, 0.5);
	color: #fff;
	padding: 1rem;
}

.wp-block-gallery[data-amp-carousel="true"] {
	display: block;
	flex-wrap: unset;
}

/* Template Styles */

.amp-wp-content,
.amp-wp-title-bar div {
		margin: 0 auto;
	max-width: 600px;
	}

html {
	background: #0a89c0;
}

body {
	background: #fff;
	color: #353535;
	font-family: Georgia, 'Times New Roman', Times, Serif;
	font-weight: 300;
	line-height: 1.75em;
}

p,
ol,
ul,
figure {
	margin: 0 0 1em;
	padding: 0;
}

a,
a:visited {
	color: #0a89c0;
}

a:hover,
a:active,
a:focus {
	color: #353535;
}

/* Quotes */

blockquote {
	color: #353535;
	background: rgba(127,127,127,.125);
	border-left: 2px solid #0a89c0;
	margin: 8px 0 24px 0;
	padding: 16px;
}

blockquote p:last-child {
	margin-bottom: 0;
}

/* UI Fonts */

.amp-wp-meta,
.amp-wp-header div,
.amp-wp-title,
.wp-caption-text,
.amp-wp-tax-category,
.amp-wp-tax-tag,
.amp-wp-comments-link,
.amp-wp-footer p,
.back-to-top {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen-Sans", "Ubuntu", "Cantarell", "Helvetica Neue", sans-serif;
}

/* Header */

.amp-wp-header {
	background-color: #0a89c0;
}

.amp-wp-header div {
	color: #fff;
	font-size: 1em;
	font-weight: 400;
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: .875em 16px;
	position: relative;
}

.amp-wp-header a {
	color: #fff;
	text-decoration: none;
}

	.amp-wp-header .amp-wp-canonical-link {
		font-size: 0.8em;
		text-decoration: underline;
		position: absolute;
		right: 18px;	}

.amp-wp-header .amp-wp-site-icon {
	/** site icon is 32px **/
	background-color: #fff;
	border: 1px solid #fff;
	border-radius: 50%;
	position: absolute;
	right: 18px;
	top: 10px;
}

/* Article */

.amp-wp-article {
	color: #353535;
	font-weight: 400;
	margin: 1.5em auto;
	max-width: 840px;
	overflow-wrap: break-word;
	word-wrap: break-word;
}

/* Article Header */

.amp-wp-article-header {
	align-items: center;
	align-content: stretch;
	display: flex;
	flex-wrap: wrap;
	justify-content: space-between;
	margin: 1.5em 16px 0;
}

.amp-wp-title {
	color: #353535;
	display: block;
	flex: 1 0 100%;
	font-weight: 900;
	margin: 0 0 .625em;
	width: 100%;
}

/* Article Meta */

.amp-wp-meta {
	color: #696969;
	display: inline-block;
	flex: 2 1 50%;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0 0 1.5em;
	padding: 0;
}

.amp-wp-article-header .amp-wp-meta:last-of-type {
	text-align: right;
}

.amp-wp-article-header .amp-wp-meta:first-of-type {
	text-align: left;
}

.amp-wp-byline amp-img,
.amp-wp-byline .amp-wp-author {
	display: inline-block;
	vertical-align: middle;
}

.amp-wp-byline amp-img {
	border: 1px solid #0a89c0;
	border-radius: 50%;
	position: relative;
	margin-right: 6px;
}

.amp-wp-posted-on {
	text-align: right;
}

/* Featured image */

.amp-wp-article-featured-image {
	margin: 0 0 1em;
}
.amp-wp-article-featured-image amp-img {
	margin: 0 auto;
}
.amp-wp-article-featured-image.wp-caption .wp-caption-text {
	margin: 0 18px;
}

/* Article Content */

.amp-wp-article-content {
	margin: 0 16px;
}

.amp-wp-article-content ul,
.amp-wp-article-content ol {
	margin-left: 1em;
}

.amp-wp-article-content .wp-caption {
	max-width: 100%;
}

.amp-wp-article-content amp-img {
	margin: 0 auto;
}

.amp-wp-article-content amp-img.alignright {
	margin: 0 0 1em 16px;
}

.amp-wp-article-content amp-img.alignleft {
	margin: 0 16px 1em 0;
}

/* Captions */

.wp-caption {
	padding: 0;
}

.wp-caption.alignleft {
	margin-right: 16px;
}

.wp-caption.alignright {
	margin-left: 16px;
}

.wp-caption .wp-caption-text {
	border-bottom: 1px solid #c2c2c2;
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0;
	padding: .66em 10px .75em;
}

/* AMP Media */

.alignwide,
.alignfull {
	clear: both;
}

amp-carousel {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}
amp-iframe,
amp-youtube,
amp-instagram,
amp-vine {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}

.amp-wp-article-content amp-carousel amp-img {
	border: none;
}

amp-carousel > amp-img > img {
	object-fit: contain;
}

.amp-wp-iframe-placeholder {
	background: #c2c2c2 url( https://daynews.cc/wp-content/plugins/amp/assets/images/placeholder-icon.png ) no-repeat center 40%;
	background-size: 48px 48px;
	min-height: 48px;
}

/* Article Footer Meta */

.amp-wp-article-footer .amp-wp-meta {
	display: block;
}

.amp-wp-tax-category,
.amp-wp-tax-tag {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 1.5em 16px;
}

.amp-wp-comments-link {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	text-align: center;
	margin: 2.25em 0 1.5em;
}

.amp-wp-comments-link a {
	border-style: solid;
	border-color: #c2c2c2;
	border-width: 1px 1px 2px;
	border-radius: 4px;
	background-color: transparent;
	color: #0a89c0;
	cursor: pointer;
	display: block;
	font-size: 14px;
	font-weight: 600;
	line-height: 18px;
	margin: 0 auto;
	max-width: 200px;
	padding: 11px 16px;
	text-decoration: none;
	width: 50%;
	-webkit-transition: background-color 0.2s ease;
			transition: background-color 0.2s ease;
}

/* AMP Footer */

.amp-wp-footer {
	border-top: 1px solid #c2c2c2;
	margin: calc(1.5em - 1px) 0 0;
}

.amp-wp-footer div {
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: 1.25em 16px 1.25em;
	position: relative;
}

.amp-wp-footer h2 {
	font-size: 1em;
	line-height: 1.375em;
	margin: 0 0 .5em;
}

.amp-wp-footer p {
	color: #696969;
	font-size: .8em;
	line-height: 1.5em;
	margin: 0 85px 0 0;
}

.amp-wp-footer a {
	text-decoration: none;
}

.back-to-top {
	bottom: 1.275em;
	font-size: .8em;
	font-weight: 600;
	line-height: 2em;
	position: absolute;
	right: 16px;
}
		td, th {
	text-align: left;
}

a, a:active, a:visited {
	text-decoration: underline;
}

	</style>
	
</head>

<body class="">


<header id="top" class="amp-wp-header">
	<div>
		<a href="https://daynews.cc/">
									<span class="amp-site-title">
				天天要聞			</span>
		</a>

										<a class="amp-wp-canonical-link" href="https://daynews.cc/technology/15491/">
				原網頁			</a>
			</div>
</header>

<article class="amp-wp-article">
	<header class="amp-wp-article-header">
		<h1 class="amp-wp-title">機器學習：AutoGluon介紹及示例</h1>
			<div class="amp-wp-meta amp-wp-byline">
					<amp-img src="https://daynews.cc/wp-content/themes/Kratos/images/default_avatar.jpeg" alt="天天要聞" width="24" height="24" layout="fixed"></amp-img>
				<span class="amp-wp-author author vcard">天天要聞</span>
	</div>
<div class="amp-wp-meta amp-wp-posted-on">
	<time datetime="2019-12-14T18:50:09+00:00">
		2019-12-14	</time>
</div>
	</header>

	
	<div class="amp-wp-article-content">
		
		<div>
<h2 class="pgc-h-arrow-right">介紹AutoGluon</h2>
<p>AutoGluon是一個新的開源 AutoML庫，可針對涉及圖像，文本和表格數據集的實際應用，自動進行深度學習（DL）和機器學習（ML）。無論您是機器學習新手還是經驗豐富的從業人員，AutoGluon都能簡化您的工作流程。使用AutoGluon，您可以僅使用幾行Python代碼來開發和完善深度學習模型。</p>
<div class="pgc-img">
  <amp-img src="http://p9.pstatp.com/large/pgc-image/cbbe8da2aaed4c2083f5c43dc0c5a770" alt="《機器學習：AutoGluon介紹及示例》" width="640" height="461" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p9.pstatp.com/large/pgc-image/cbbe8da2aaed4c2083f5c43dc0c5a770" alt="《機器學習：AutoGluon介紹及示例》" width="640" height="461" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<h2 class="pgc-h-arrow-right">主要特點</h2>
<p>從歷史上看，要創建機器學習模型，需要大量的背景知識，經驗和人力。數據準備，特徵工程，驗證拆分，缺失值處理和模型選擇只是機器學習應用程序必須解決的許多任務中的一部分。一個特別困難的任務是選擇超參數。</p>
<p>超參數代表用戶在構建模型時必須做出的許多選擇，例如數據處理步驟，神經網路體系結構以及訓練期間使用的優化程序。每個超參數都以不透明的方式影響機器學習模型的預測性能，而越強大的模型(如深度神經網路)需要調優的超參數越多。輕微的超參數修改可能會顯著地改變模型的質量。由於通常不清楚如何做出這些決策，開發人員通常手動調整他們的ML管道的各個方面，這可能需要多次迭代和艱苦的人力工作。<br>AutoGluon將前面提到的所有任務都自動化，從而創造了一種真正無需手動的體驗。AutoGluon將利用可用的計算資源來找到最強的ML方法。<br>AutoGluon使您能夠自動實現圖像分類、對象檢測、文本分類等監督學習任務。每個任務的超參數通過貝葉斯優化、超帶和強化學習等優化演算法自動選擇。使用AutoGluon，您不必熟悉底層模型，因為所有超參數都將自動調優到默認範圍內，這些默認範圍對於特定的任務和模型來說性能良好。<br>對於專業的ML從業人員，AutoGluon允許輕鬆地自定義此過程。例如，您可以為某些超參數指定要值範圍，也可以使用AutoGluon自動調整自定義模型的各個方面。如果您可以訪問多台機器，AutoGluon可以很容易地將其計算分布到這些機器上，以便更快地返回經過訓練的模型。</p>
<h2 class="pgc-h-arrow-right">AutoGluon示例</h2>
<p><strong>安裝</strong></p>
<pre># CUDA 10.0 and a GPU for object detection is recommended<br># We install MXNet to utilize deep learning models<br>pip install --upgrade mxnet-cu100<br>pip install autogluon</pre>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/4be66ac3997643c5b0fece1c8a0838a5" alt="《機器學習：AutoGluon介紹及示例》" width="678" height="106" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/4be66ac3997643c5b0fece1c8a0838a5" alt="《機器學習：AutoGluon介紹及示例》" width="678" height="106" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p><strong>對象檢測示例</strong></p>
<p>我們以對象檢測的任務為例來演示AutoGluon的簡單介面。在對象檢測中，不僅要識別圖像中的對象，而且要用邊界框定位它們。</p>
<p>我們將使用AutoGluon在一個用於演示目的(以確保快速運行時)的數據集上訓練一個對象檢測器。數據集是使用VOC數據集的摩托車類別生成的。在下面的Python代碼中，我們首先導入AutoGluon，將將對象檢測指定為任務，將數據下載到我們的機器上，最後將數據載入到Python中:</p>
<pre>import autogluon as ag<br>from autogluon import ObjectDetection as task<br>url = 'https://autogluon.s3.amazonaws.com/datasets/tiny_motorbike.zip'<br>data_dir = ag.unzip(ag.download(url))<br>dataset = task.Dataset(data_dir, classes=('motorbike',))</pre>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/a5c8c755c91e44c1b9ab8b1c6237cc44" alt="《機器學習：AutoGluon介紹及示例》" width="679" height="127" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/a5c8c755c91e44c1b9ab8b1c6237cc44" alt="《機器學習：AutoGluon介紹及示例》" width="679" height="127" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>接下來，我們可以通過調用fit()函數來使用AutoGluon訓練一個檢測器模型:</p>
<pre>detector = task.fit(dataset)</pre>
<p>在這個對fit()的調用中，AutoGluon在不同的網路配置和優化超參數下訓練許多模型，選擇其中最好的作為最終返回的檢測器。在沒有任何用戶輸入的情況下，對fit()的調用還自動利用了最新的深度學習技術，例如預訓練的YOLOv3網路的遷移學習。我們可以使用predict()方法在新圖像上測試訓練過的檢測器:</p>
<pre>url = 'https://autogluon.s3.amazonaws.com/images/object_detection_example.png'<br>filename = ag.download(url)<br>index, probabilities, locations = detector.predict(filename)</pre>
<div class="pgc-img">
  <amp-img src="http://p9.pstatp.com/large/pgc-image/03356dcea516427aa83590ce5541483a" alt="《機器學習：AutoGluon介紹及示例》" width="666" height="81" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p9.pstatp.com/large/pgc-image/03356dcea516427aa83590ce5541483a" alt="《機器學習：AutoGluon介紹及示例》" width="666" height="81" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/c31dd45b8b5b46e0987f8f54ec780245" alt="《機器學習：AutoGluon介紹及示例》" width="386" height="252" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/c31dd45b8b5b46e0987f8f54ec780245" alt="《機器學習：AutoGluon介紹及示例》" width="386" height="252" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>AutoGluon的predict函數自動載入測試圖像，並輸出每個被檢測對象的預測對象類別、類概率和邊界框位置。將自動生成如上所示的可視化圖像。</p>
<p><strong>表格數據示例</strong></p>
<p>最常見的數據形式是表格數據集。它們由結構化數據組成，通常位於CSV文件或資料庫中。在表格數據集中，每一列代表某個變數的測量值(也稱為特徵)，每一行代表單獨的數據點。AutoGluon可用於訓練基於同一行中的其他列來預測特定列值的模型，並且能夠泛化到以前未見過的實例。<br>我們將要訓練的數據集是成人收入分類數據集。該數據集包含約48,000個人的信息，包括數字特徵（例如年齡）和分類特徵（例如職業）。該數據集通常用於預測個人收入。在此示例中，我們將預測一個人的年收入是否超過50,000美元。我們將使用80％的數據來訓練，並使用20％的數據來測試生成的AutoGluon預測器。使用AutoGluon，無需指定驗證數據。AutoGluon將使用提供的訓練數據最優地分配驗證集。<br>舉例來說，在Python代碼中，首先導入AutoGluon並指定一個任務，在這個任務中，我們將使用TabularPrediction處理表格數據。然後我們從S3上的CSV文件載入數據集。只需調用一次fit()， AutoGluon就可以處理數據並訓練一個稱為「預測器」的ML模型集合，該模型能夠預測數據中的「類」變數。它將使用其他列作為預測特徵，如個人的年齡、職業和教育程度。這個模型的集合包括ML中經過測試的演算法，如LightGBM、CatBoost和深度神經網路，它們始終優於邏輯回歸等更傳統的ML模型。<br>注意，我們不需要進行任何數據處理，特徵工程設計，甚至不需要聲明預測問題的類型。AutoGluon自動準備數據並推斷我們的問題是回歸還是分類(包括它是二元還是多元)。經過訓練的預測器模型將保存到task.fit()調用中指定的位置。</p>
<pre>from autogluon import TabularPrediction as task<br>train_path = 'https://autogluon.s3.amazonaws.com/datasets/AdultIncomeBinaryClassification/train_data.csv'<br>train_data = task.Dataset(file_path=train_path)<br>predictor = task.fit(train_data, label='class', output_directory='ag-example-out/')</pre>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/241623edfb6444fd86519b90d32493d6" alt="《機器學習：AutoGluon介紹及示例》" width="857" height="105" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/241623edfb6444fd86519b90d32493d6" alt="《機器學習：AutoGluon介紹及示例》" width="857" height="105" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>現在我們的預測器模型已經訓練完畢，我們將對以前看不見的測試數據進行預測。我們可以直接使用返回的預測變數，也可以從指定的輸出目錄中載入它。</p>
<pre>predictor = task.load('ag-example-out/')<br>test_path = 'https://autogluon.s3.amazonaws.com/datasets/AdultIncomeBinaryClassification/test_data.csv'<br>test_data = task.Dataset(file_path=test_path)<br>y_test = test_data['class']<br>test_data_nolabel = test_data.drop(labels=['class'],axis=1)<br>y_pred = predictor.predict(test_data_nolabel)<br>y_pred_proba = predictor.predict_proba(test_data_nolabel)<br>print(list(y_pred[:5]))<br>print(list(y_pred_proba[:5]))</pre>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/e47f2e40564a43deb84daf29e4ad72b0" alt="《機器學習：AutoGluon介紹及示例》" width="846" height="207" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/e47f2e40564a43deb84daf29e4ad72b0" alt="《機器學習：AutoGluon介紹及示例》" width="846" height="207" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>[‘&lt;= 50K’，'&lt;= 50K’，’&gt; 50K’，'&lt;= 50K’，'&lt;= 50K’]<br>[0.077471，0.0093894，0.973065，0.0021249，0.001387]<br>現在我們來看一下模型排行榜:</p>
<pre>leaderboard = predictor.leaderboard(test_data)</pre>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/1e8e4b4a974a4066b2ecd26464404583" alt="《機器學習：AutoGluon介紹及示例》" width="640" height="214" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/1e8e4b4a974a4066b2ecd26464404583" alt="《機器學習：AutoGluon介紹及示例》" width="640" height="214" class=""></noscript></amp-img>
<p class="pgc-img-caption">AutoGluon的模型排行榜</p>

</div>
<p>該排行榜顯示了AutoGluon訓練的每個模型，它們在測試和驗證數據上的得分以及訓練時間（以秒為單位）。可以看出，weighted_ensemble在驗證和測試集上表現得最好，達到了87.76%的準確性。</p>
<h2 class="pgc-h-arrow-right">最後</h2>
<p>在本文中，我們介紹了AutoGluon，它旨在為ML專家和新手提供最佳的機器學習和深度學習體驗。</p>
</div>
	</div>

	<footer class="amp-wp-article-footer">
			<div class="amp-wp-meta amp-wp-tax-category">
		分類: <a href="https://daynews.cc/technology/" rel="category tag">科技</a>	</div>

		<div class="amp-wp-meta amp-wp-comments-link">
		<a href="https://daynews.cc/technology/15491/#comments">
			寫評論		</a>
	</div>
	</footer>
</article>

<footer class="amp-wp-footer">
	<div>
		<h2>天天要聞</h2>
		<a href="#top" class="back-to-top">返回頂部</a>
	</div>
</footer>


<amp-analytics id="354f0d2beeef" type="baiduanalytics"><script type="application/json">{"vars":{"token":"882f12dcdadf8f87fabf76b550649115"},"triggers":{"trackPageview":{"on":"visible","request":"pageview"}}}</script></amp-analytics>
</body>
</html>
<!-- This is the static html file -->