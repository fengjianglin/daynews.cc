<!doctype html>
<html amp lang="zh-TW">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
	<script type='application/ld+json' class='yoast-schema-graph yoast-schema-graph--main'>{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://daynews.cc/#website","url":"https://daynews.cc/","name":"\u5929\u5929\u8981\u805e","description":"\u4e00\u7db2\u6253\u76e1\u5168\u7db2\u6700\u65b0\u8cc7\u8a0a\u6700\u71b1\u982d\u689d\u65b0","potentialAction":{"@type":"SearchAction","target":"https://daynews.cc/?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://daynews.cc/technology/10220#primaryimage","url":"http://p9.pstatp.com/large/pgc-image/Rjm7XFREsRlxK"},{"@type":"WebPage","@id":"https://daynews.cc/technology/10220#webpage","url":"https://daynews.cc/technology/10220","inLanguage":"zh-TW","name":"\u83ef\u70ba\u958b\u6e90\u9810\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\u300c\u54ea\u5412\u300d - \u5929\u5929\u8981\u805e","isPartOf":{"@id":"https://daynews.cc/#website"},"primaryImageOfPage":{"@id":"https://daynews.cc/technology/10220#primaryimage"},"datePublished":"2019-12-06T07:15:13+00:00","dateModified":"2019-12-06T07:15:13+00:00","author":{"@id":"https://daynews.cc/#/schema/person/038ceb5ed68cf11f9ec94ba43c7ff55d"}},{"@type":["Person"],"@id":"https://daynews.cc/#/schema/person/038ceb5ed68cf11f9ec94ba43c7ff55d","name":"\u5929\u5929\u8981\u805e","image":{"@type":"ImageObject","@id":"https://daynews.cc/#authorlogo","url":"https://secure.gravatar.com/avatar/e786821a74ef0467825a7d60183307bc?s=96&d=mm&r=g","caption":"\u5929\u5929\u8981\u805e"},"sameAs":[]}]}</script>
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:description" content="一個月前，在「AICon 全球人工智慧與機器學習技術大會」上，華為諾亞方舟實驗首席科學家劉群剛分享了新發布的中文預訓練語言模型 NEZHA（哪吒）；就在這兩天，NEZHA 已在 Github 上開源，同時開源的還有壓縮 BERT 模型「TinyBERT」，它在推理時大小可縮小 7.5 倍，並且速度加快 9.4 倍。 可以看到的是近兩年預訓……" />
<meta name="twitter:title" content="華為開源預訓練語言模型「哪吒」 - 天天要聞" />
<meta name="twitter:image" content="http://p9.pstatp.com/large/pgc-image/Rjm7XFREsRlxK" />
<meta property="og:locale" content="zh_TW" />
<meta property="og:type" content="article" />
<meta property="og:title" content="華為開源預訓練語言模型「哪吒」 - 天天要聞" />
<meta property="og:description" content="一個月前，在「AICon 全球人工智慧與機器學習技術大會」上，華為諾亞方舟實驗首席科學家劉群剛分享了新發布的中文預訓練語言模型 NEZHA（哪吒）；就在這兩天，NEZHA 已在 Github 上開源，同時開源的還有壓縮 BERT 模型「TinyBERT」，它在推理時大小可縮小 7.5 倍，並且速度加快 9.4 倍。 可以看到的是近兩年預訓……" />
<meta property="og:url" content="https://daynews.cc/technology/10220" />
<meta property="og:site_name" content="天天要聞" />
<meta property="article:section" content="科技" />
<meta property="article:published_time" content="2019-12-06T07:15:13+00:00" />
	<title>華為開源預訓練語言模型「哪吒」 - 天天要聞</title>
		<link rel="canonical" href="https://daynews.cc/technology/10220" />
	<script type='text/javascript' src='https://cdn.ampproject.org/v0.js' async></script>
<script type='text/javascript' src='https://cdn.ampproject.org/v0/amp-analytics-0.1.js' async custom-element="amp-analytics"></script>
<style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript><meta name="generator" content="AMP Plugin v1.4.1; mode=reader; experiences=website"><meta name="generator" content="WordPress 5.2.4" />
	<style amp-custom>
		/* Generic WP styling */

.alignright {
	float: right;
}

.alignleft {
	float: left;
}

.aligncenter {
	display: block;
	text-align: center;
	margin-left: auto;
	margin-right: auto;
}

.amp-wp-enforced-sizes {
	/** Our sizes fallback is 100vw, and we have a padding on the container; the max-width here prevents the element from overflowing. **/
	max-width: 100%;
	margin: 0 auto;
}


/*
 * Prevent cases of amp-img converted from img to appear with stretching by using object-fit to scale.
 * See <https://github.com/ampproject/amphtml/issues/21371#issuecomment-475443219>.
 * Also use object-fit:contain in worst case scenario when we can't figure out dimensions for an image.
 * Additionally, in side of \AMP_Img_Sanitizer::determine_dimensions() it could $amp_img->setAttribute( 'object-fit', 'contain' )
 * so that the following rules wouldn't be needed.
 */
amp-img.amp-wp-enforced-sizes[layout="intrinsic"] > img,
amp-anim.amp-wp-enforced-sizes[layout="intrinsic"] > img {
	object-fit: contain;
}

amp-fit-text blockquote,
amp-fit-text h1,
amp-fit-text h2,
amp-fit-text h3,
amp-fit-text h4,
amp-fit-text h5,
amp-fit-text h6 {
	font-size: inherit;
}

/**
 * Override a style rule in Twenty Sixteen and Twenty Seventeen.
 * It set display:none for audio elements.
 * This selector is the same, though it adds body and uses amp-audio instead of audio.
 */
body amp-audio:not([controls]) {
	display: inline-block;
	height: auto;
}

/*
 * Style the default template messages for submit-success, submit-error, and submitting. These elements are inserted
 * by the form sanitizer when a POST form lacks the action-xhr attribute.
 */
.amp-wp-default-form-message > p {
	margin: 1em 0;
	padding: 0.5em;
}

.amp-wp-default-form-message[submitting] > p,
.amp-wp-default-form-message[submit-success] > p.amp-wp-form-redirecting {
	font-style: italic;
}

.amp-wp-default-form-message[submit-success] > p:not(.amp-wp-form-redirecting) {
	border: solid 1px #008000;
	background-color: #90ee90;
	color: #000;
}

.amp-wp-default-form-message[submit-error] > p {
	border: solid 1px #f00;
	background-color: #ffb6c1;
	color: #000;
}

/* Prevent showing empty success message in the case of an AMP-Redirect-To response header. */
.amp-wp-default-form-message[submit-success] > p:empty {
	display: none;
}

amp-carousel .amp-wp-gallery-caption {
	position: absolute;
	bottom: 0;
	left: 0;
	right: 0;
	text-align: center;
	background-color: rgba(0, 0, 0, 0.5);
	color: #fff;
	padding: 1rem;
}

.wp-block-gallery[data-amp-carousel="true"] {
	display: block;
	flex-wrap: unset;
}

/* Template Styles */

.amp-wp-content,
.amp-wp-title-bar div {
		margin: 0 auto;
	max-width: 600px;
	}

html {
	background: #0a89c0;
}

body {
	background: #fff;
	color: #353535;
	font-family: Georgia, 'Times New Roman', Times, Serif;
	font-weight: 300;
	line-height: 1.75em;
}

p,
ol,
ul,
figure {
	margin: 0 0 1em;
	padding: 0;
}

a,
a:visited {
	color: #0a89c0;
}

a:hover,
a:active,
a:focus {
	color: #353535;
}

/* Quotes */

blockquote {
	color: #353535;
	background: rgba(127,127,127,.125);
	border-left: 2px solid #0a89c0;
	margin: 8px 0 24px 0;
	padding: 16px;
}

blockquote p:last-child {
	margin-bottom: 0;
}

/* UI Fonts */

.amp-wp-meta,
.amp-wp-header div,
.amp-wp-title,
.wp-caption-text,
.amp-wp-tax-category,
.amp-wp-tax-tag,
.amp-wp-comments-link,
.amp-wp-footer p,
.back-to-top {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen-Sans", "Ubuntu", "Cantarell", "Helvetica Neue", sans-serif;
}

/* Header */

.amp-wp-header {
	background-color: #0a89c0;
}

.amp-wp-header div {
	color: #fff;
	font-size: 1em;
	font-weight: 400;
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: .875em 16px;
	position: relative;
}

.amp-wp-header a {
	color: #fff;
	text-decoration: none;
}

	.amp-wp-header .amp-wp-canonical-link {
		font-size: 0.8em;
		text-decoration: underline;
		position: absolute;
		right: 18px;	}

.amp-wp-header .amp-wp-site-icon {
	/** site icon is 32px **/
	background-color: #fff;
	border: 1px solid #fff;
	border-radius: 50%;
	position: absolute;
	right: 18px;
	top: 10px;
}

/* Article */

.amp-wp-article {
	color: #353535;
	font-weight: 400;
	margin: 1.5em auto;
	max-width: 840px;
	overflow-wrap: break-word;
	word-wrap: break-word;
}

/* Article Header */

.amp-wp-article-header {
	align-items: center;
	align-content: stretch;
	display: flex;
	flex-wrap: wrap;
	justify-content: space-between;
	margin: 1.5em 16px 0;
}

.amp-wp-title {
	color: #353535;
	display: block;
	flex: 1 0 100%;
	font-weight: 900;
	margin: 0 0 .625em;
	width: 100%;
}

/* Article Meta */

.amp-wp-meta {
	color: #696969;
	display: inline-block;
	flex: 2 1 50%;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0 0 1.5em;
	padding: 0;
}

.amp-wp-article-header .amp-wp-meta:last-of-type {
	text-align: right;
}

.amp-wp-article-header .amp-wp-meta:first-of-type {
	text-align: left;
}

.amp-wp-byline amp-img,
.amp-wp-byline .amp-wp-author {
	display: inline-block;
	vertical-align: middle;
}

.amp-wp-byline amp-img {
	border: 1px solid #0a89c0;
	border-radius: 50%;
	position: relative;
	margin-right: 6px;
}

.amp-wp-posted-on {
	text-align: right;
}

/* Featured image */

.amp-wp-article-featured-image {
	margin: 0 0 1em;
}
.amp-wp-article-featured-image amp-img {
	margin: 0 auto;
}
.amp-wp-article-featured-image.wp-caption .wp-caption-text {
	margin: 0 18px;
}

/* Article Content */

.amp-wp-article-content {
	margin: 0 16px;
}

.amp-wp-article-content ul,
.amp-wp-article-content ol {
	margin-left: 1em;
}

.amp-wp-article-content .wp-caption {
	max-width: 100%;
}

.amp-wp-article-content amp-img {
	margin: 0 auto;
}

.amp-wp-article-content amp-img.alignright {
	margin: 0 0 1em 16px;
}

.amp-wp-article-content amp-img.alignleft {
	margin: 0 16px 1em 0;
}

/* Captions */

.wp-caption {
	padding: 0;
}

.wp-caption.alignleft {
	margin-right: 16px;
}

.wp-caption.alignright {
	margin-left: 16px;
}

.wp-caption .wp-caption-text {
	border-bottom: 1px solid #c2c2c2;
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0;
	padding: .66em 10px .75em;
}

/* AMP Media */

.alignwide,
.alignfull {
	clear: both;
}

amp-carousel {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}
amp-iframe,
amp-youtube,
amp-instagram,
amp-vine {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}

.amp-wp-article-content amp-carousel amp-img {
	border: none;
}

amp-carousel > amp-img > img {
	object-fit: contain;
}

.amp-wp-iframe-placeholder {
	background: #c2c2c2 url( https://daynews.cc/wp-content/plugins/amp/assets/images/placeholder-icon.png ) no-repeat center 40%;
	background-size: 48px 48px;
	min-height: 48px;
}

/* Article Footer Meta */

.amp-wp-article-footer .amp-wp-meta {
	display: block;
}

.amp-wp-tax-category,
.amp-wp-tax-tag {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 1.5em 16px;
}

.amp-wp-comments-link {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	text-align: center;
	margin: 2.25em 0 1.5em;
}

.amp-wp-comments-link a {
	border-style: solid;
	border-color: #c2c2c2;
	border-width: 1px 1px 2px;
	border-radius: 4px;
	background-color: transparent;
	color: #0a89c0;
	cursor: pointer;
	display: block;
	font-size: 14px;
	font-weight: 600;
	line-height: 18px;
	margin: 0 auto;
	max-width: 200px;
	padding: 11px 16px;
	text-decoration: none;
	width: 50%;
	-webkit-transition: background-color 0.2s ease;
			transition: background-color 0.2s ease;
}

/* AMP Footer */

.amp-wp-footer {
	border-top: 1px solid #c2c2c2;
	margin: calc(1.5em - 1px) 0 0;
}

.amp-wp-footer div {
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: 1.25em 16px 1.25em;
	position: relative;
}

.amp-wp-footer h2 {
	font-size: 1em;
	line-height: 1.375em;
	margin: 0 0 .5em;
}

.amp-wp-footer p {
	color: #696969;
	font-size: .8em;
	line-height: 1.5em;
	margin: 0 85px 0 0;
}

.amp-wp-footer a {
	text-decoration: none;
}

.back-to-top {
	bottom: 1.275em;
	font-size: .8em;
	font-weight: 600;
	line-height: 2em;
	position: absolute;
	right: 16px;
}
		td, th {
	text-align: left;
}

a, a:active, a:visited {
	text-decoration: underline;
}

	</style>
	
	<script async custom-element="amp-auto-ads" 
			src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js"></script>
	<script async custom-element="amp-ad" src="https://cdn.ampproject.org/v0/amp-ad-0.1.js"></script>
	
</head>

<body class="">
	<amp-auto-ads type="adsense" data-ad-client="ca-pub-8261739837930821"></amp-auto-ads>

<header id="top" class="amp-wp-header">
	<div>
		<a href="https://daynews.cc/">
									<span class="amp-site-title">
				天天要聞			</span>
		</a>

										<a class="amp-wp-canonical-link" href="https://daynews.cc/technology/10220">
				原網頁			</a>
			</div>
</header>

<article class="amp-wp-article">
	<header class="amp-wp-article-header">
		<h1 class="amp-wp-title">華為開源預訓練語言模型「哪吒」</h1>
			<div class="amp-wp-meta amp-wp-byline">
					<amp-img src="https://daynews.cc/wp-content/themes/Kratos/images/default_avatar.jpeg" alt="天天要聞" width="24" height="24" layout="fixed"></amp-img>
				<span class="amp-wp-author author vcard">天天要聞</span>
	</div>
<div class="amp-wp-meta amp-wp-posted-on">
	<time datetime="2019-12-06T15:15:13+00:00">
		2019-12-06	</time>
</div>
	</header>

	
	<div class="amp-wp-article-content">
		<amp-ad width="100vw" height="320"
			 type="adsense"
			 data-ad-client="ca-pub-8261739837930821"
			 data-ad-slot="2502207318"
			 data-auto-format="rspv"
			 data-full-width="">
		  <div overflow=""></div>
		</amp-ad>
		
		<div>
<p>一個月前，在「AICon 全球人工智慧與機器學習技術大會」上，華為諾亞方舟實驗首席科學家劉群剛分享了新發布的中文預訓練語言模型 NEZHA（哪吒）；就在這兩天，NEZHA 已在 Github 上開源，同時開源的還有壓縮 BERT 模型「TinyBERT」，它在推理時大小可縮小 7.5 倍，並且速度加快 9.4 倍。</p>
<p>可以看到的是近兩年預訓練模型的發展非常快速，從 Word2Vec 到 ULMFiT、CoVe 再到 BERT、XLNET 等，都各有特點且在不斷完善中。聚焦於「多項中文 NLP 任務性能」的 NEZHA 也有亮眼的性能升級。在此，雷鋒網 AI 開發者將 NEZHA 詳細內容及 TinyBERT 相關地址整理如下。</p>
<div class="pgc-img">
  <amp-img src="http://p9.pstatp.com/large/pgc-image/Rjm7XFREsRlxK" alt="《華為開源預訓練語言模型「哪吒」》" width="640" height="332" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p9.pstatp.com/large/pgc-image/Rjm7XFREsRlxK" alt="《華為開源預訓練語言模型「哪吒」》" width="640" height="332" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>NEZHA 開發背景</p>
<p>預訓練語言模型本質上，就是神經網路語言模型。它主要有兩個特點，即：可以使用大規模無標註純文本語料進行訓練，以及可以用於各類下游 NLP 任務，各項性能指標均獲得大幅度提高，並可以將各類下游任務的解決方案統一簡化為集中固定的 fine-tune 框架。</p>
<p>預訓練語言模型通常有兩個大類型。一類是 Encoder，用於自然語言理解，輸入整個文章，用於自然語言理解；另一類是 Decoder，是解碼式的，用於自然語言生成，只能來看到已經生成的內容，看不到沒有生成的內容，這兩類模型有所區別。</p>
<p>更直觀來看，github 上來自清華大學的兩位同學——王曉智和張正彥（在讀本科生）整理的一份關於預訓練模型的關係圖，則可以從功能方面更簡單明了的幫我們理解該類模型類別。</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/Rjm7XFzAAWM8Yq" alt="《華為開源預訓練語言模型「哪吒」》" width="640" height="361" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/Rjm7XFzAAWM8Yq" alt="《華為開源預訓練語言模型「哪吒」》" width="640" height="361" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>預訓練模型的關係圖</p>
<blockquote>
<p>更多詳細內容，可參見 PLM 論文整理 Github 項目地址：</p>
<p>https://github.com/thunlp/PLMpapers</p>
</blockquote>
<p>圖中列出了 BERT、GPT、XLNet、ERNIE 等模型以及它們之間的關係，並擬出了一份相關的論文列表。列表把預訓練模型主要分為了三個部分，包括：模型、知識蒸餾與模型壓縮。按照這樣的分類，TinyBERT 模型則可以歸類為「知識蒸餾與模型壓縮」部分；NEZHA 則歸為「模型」部分。</p>
<p>而根據研究結果顯示，近年來的模型大多將重心落到了數據與算力部分。與早期的 ResNet（視覺模型）模型參數相比，數據顯示 GPT1 為 100M，BERT large 為 340M，GPT2 為 1.5BN，GPT-2 8B 為 8.3BN。</p>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/Rjm7XGTEPwOVl2" alt="《華為開源預訓練語言模型「哪吒」》" width="640" height="274" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/Rjm7XGTEPwOVl2" alt="《華為開源預訓練語言模型「哪吒」》" width="640" height="274" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>預訓練語言模型研究結果</p>
<p>因此，在預訓練模型開發過程中，華為諾亞方舟研究者提出了一種為基於 transformer 的模型設計的知識蒸餾方法——壓縮 BERT 模型 TinyBERT；該模型大小不到 BERT 的 1/7，但速度是 BERT 的 9 倍多。</p>
<p>而在模型方面，他們選擇在內部重現了 Google Bert-base 和 Bert-large 的實驗；利用 BERT 的代碼，實現了 OpenAI GPT-2 模型；實現基於 GPU 多卡多機並行訓練，並且對訓練過程進行了優化，提高訓練效率，最終得到了「多中文 NLP 任務」預訓練模型 NEZHA。</p>

<p>三頭六臂 NEZHA（哪吒）</p>
<p>儘管這一預訓練模型 NEZHA 的名稱聽起來有些匪夷所思，但它的開發者們將其視為「無所不能，可以解決不同任務」的寓意。在這個模型中，除了之前提到的重現、多卡多機並行訓練之外，主要有兩項改進，即：函數式相對位置編碼與全詞覆蓋的實現。</p>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/Rjm7XGu4nx7rkO" alt="《華為開源預訓練語言模型「哪吒」》" width="640" height="285" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/Rjm7XGu4nx7rkO" alt="《華為開源預訓練語言模型「哪吒」》" width="640" height="285" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p><strong>一、函數式相對位置編碼</strong></p>
<p>位置編碼有函數式和參數式兩種，函數式通過定義函數直接計算就可以了。參數式中位置編碼涉及兩個概念，一個是距離；二是維度。其中，Word Embedding 一般有幾百維，每一維各有一個值，一個位置編碼的值正是通過位置和維度兩個參數來確定。</p>
<p>NEZHA 預訓練模型則採用了函數式相對位置編碼，其輸出與注意力得分的計算涉及到他們相對位置的正弦函數，這一靈感正是來源於 Transformer 的絕對位置編碼，而相對位置編碼則解決了在 Transformer 中，每個詞之間因為互不知道相隔的距離引發的一系列資源佔用問題。</p>
<div class="pgc-img">
  <amp-img src="http://p9.pstatp.com/large/pgc-image/Rjm7XH46KuD6Ao" alt="《華為開源預訓練語言模型「哪吒」》" width="281" height="207" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p9.pstatp.com/large/pgc-image/Rjm7XH46KuD6Ao" alt="《華為開源預訓練語言模型「哪吒」》" width="281" height="207" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>位置編碼模型</p>
<p>具體而言，Transformer 最早只考慮了絕對位置編碼，而且是函數式的；後來 BERT 的提出就使用了參數式，而參數式訓練則會受收到句子長度的影響，BERT 起初訓練的句子最長為 512，如果只訓練到 128 長度的句子，在 128~520 之間的位置參數就無法獲得，所以必須要訓練更長的語料來確定這一部分的參數。</p>
<p>而在 NEZHA 模型中，距離和維度都是由正弦函數導出的，並且在模型訓練期間是固定的。也就是說，位置編碼的每個維度對應一個正弦，不同維度的正弦函數具有不同的波長，而選擇固定正弦函數，則可以使該模型具有更強的擴展性；即當它遇到比訓練中序列長度更長的序列時，依然可以發揮作用。函數式相對位置編碼公式，如下圖所示：</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/Rjm7XUb5zZXQgi" alt="《華為開源預訓練語言模型「哪吒」》" width="740" height="164" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/Rjm7XUb5zZXQgi" alt="《華為開源預訓練語言模型「哪吒」》" width="740" height="164" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p><strong>二、全詞覆蓋</strong></p>
<p>現在的神經網路模型無論是在語言模型還是機器翻譯任務中，都會用到一個詞表；而在 Softmax 時，每個詞都要嘗試比較一下。每次運算時，所有詞要都在詞表中對比一遍，往往一個詞表會包含幾萬個詞，而機器翻譯則經常達到六七萬個詞，因此，詞表是語言模型運算中較大的瓶頸。</p>
<p>而 NEZHA 預訓練模型，則採用了全詞覆蓋（WWM）策略，當一個漢字被覆蓋時，屬於同一個漢字的其他漢字都被一起覆蓋。該策略被證明比 BERT 中的隨機覆蓋訓練（即每個符號或漢字都被隨機屏蔽）更有效。</p>
<div class="pgc-img">
  <amp-img src="http://p9.pstatp.com/large/pgc-image/Rjm7XUzHmJca3i" alt="《華為開源預訓練語言模型「哪吒」》" width="640" height="261" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p9.pstatp.com/large/pgc-image/Rjm7XUzHmJca3i" alt="《華為開源預訓練語言模型「哪吒」》" width="640" height="261" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>BERT 中的隨機覆蓋</p>
<p>在 NEZHA 的 WWM 實現中，研究者使用了一個標記化工具 Jieba2 進行中文分詞（即尋找中文單詞的邊界）。在 WWM 訓練數據中，每個樣本包含多個覆蓋漢字，覆蓋漢字的總數約佔其長度的 12%，隨機替換的占 1.5%，儘管這樣預測整個詞運算難度有所增加，但最終取得的效果更好。</p>
<p><strong>三、混合精度訓練及 LAMB 優化器</strong></p>
<p>在 NEZHA 模型的預訓練中，研究者採用了混合精度訓練技術。該技術可以使訓練速度提高 2-3 倍，同時也減少了模型的空間消耗，從而可以利用較大的批量。</p>
<p>傳統的深度神經網路訓練使用 FP32（即單精度浮點格式）來表示訓練中涉及的所有變數（包括模型參數和梯度）；而混合精度訓練在訓練中採用了多精度。具體而言，它重點保證模型中權重的單精度副本（稱為主權重），即在每次訓練迭代中，將主權值舍入 FP16（即半精度浮點格式），並使用 FP16 格式存儲的權值、激活和梯度執行向前和向後傳遞；最後將梯度轉換為 FP32 格式，並使用 FP32 梯度更新主權重。</p>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/Rjm7XVIG7C8yol" alt="《華為開源預訓練語言模型「哪吒」》" width="670" height="523" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/Rjm7XVIG7C8yol" alt="《華為開源預訓練語言模型「哪吒」》" width="670" height="523" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>LAMB 優化器則是為專為深度神經元網路的大批量同步分布訓練而設計。儘管大小批量 DNN 訓練是加快 DNN 訓練速度的有效方法，但是如果不仔細調整學習速率的調度，當批量處理的大小超過某個閾值時，模型的性能可能會受到很大影響。</p>
<p>LAMB 優化器則不需要手動調整學習速率，而是採用了一種通用的自適應策略。優化器通過使用非常大的批量處理大小（實驗中高達 30k 以上）來加速 BERT 的訓練，而不會導致性能損失，甚至在許多任務中獲得最先進的性能。值得注意的是，BERT 的訓練時間最終從 3 天顯著縮短到 76 分鐘。</p>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/Rjm7XXu8P4TLkx" alt="《華為開源預訓練語言模型「哪吒」》" width="510" height="343" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/Rjm7XXu8P4TLkx" alt="《華為開源預訓練語言模型「哪吒」》" width="510" height="343" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>NEZHA 實驗結果</p>
<p>實驗通過對各種自然語言理解（NLU）任務進行微調來測試預訓練模型的性能，並將 NEZHA 模型和最先進的漢語預訓練語言模型：谷歌 BERT（漢語版），BERT-WWM 以及 ERNIE 進行了對比，最終結果如下：</p>
<div class="pgc-img">
  <amp-img src="http://p1.pstatp.com/large/pgc-image/Rjm7XYDE46gIFW" alt="《華為開源預訓練語言模型「哪吒」》" width="740" height="239" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p1.pstatp.com/large/pgc-image/Rjm7XYDE46gIFW" alt="《華為開源預訓練語言模型「哪吒」》" width="740" height="239" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<p>NEZHA 實驗結果</p>
<p>可以看到，NEZHA 在大部分情況下，都取得了相較更好的性能；尤其在 PD-NER 任務下，NEZHA 最高達到了 97.87 分。另一個表現較亮眼的模型還有 ERNIE Baidu 2.0，頗有超越 NEZHA 的趨勢。關於這個情況，論文中作者也解釋到，由於實驗設置或微調方法可能存在差異，比較可能不完全公平，之後其它模型新版發布後，他們將在相同的設置下對其進行評估並更新此報告。</p>
<div class="pgc-img">
  <amp-img src="http://p3.pstatp.com/large/pgc-image/Rjm7XsW2Zx4Oy2" alt="《華為開源預訓練語言模型「哪吒」》" width="534" height="322" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="http://p3.pstatp.com/large/pgc-image/Rjm7XsW2Zx4Oy2" alt="《華為開源預訓練語言模型「哪吒」》" width="534" height="322" class=""></noscript></amp-img>
<p class="pgc-img-caption">
</p></div>
<blockquote>
<p>更多詳情，可參見 NEZHA 論文地址：</p>
<p>https://arxiv.org/pdf/1909.00204.pdf</p>

<p>關於知識蒸餾模型 TinyBERT 詳細解讀，可參考往期內容：</p>
<p>https://mp.weixin.qq.com/s/f2vxlhaGW1wnu8UYrvh-tA</p>
<p>Github 開源地址（包含 NEZHA 與 TinyBERT ）：</p>
<p>https://github.com/huawei-noah/Pretrained-Language-Model</p>
</blockquote>
</div>
	</div>

	<footer class="amp-wp-article-footer">
			<div class="amp-wp-meta amp-wp-tax-category">
		分類: <a href="https://daynews.cc/technology" rel="category tag">科技</a>	</div>

		<div class="amp-wp-meta amp-wp-comments-link">
		<a href="https://daynews.cc/technology/10220#comments">
			寫評論		</a>
	</div>
	</footer>
</article>

<footer class="amp-wp-footer">
	<div>
		<h2>天天要聞</h2>
		<a href="#top" class="back-to-top">返回頂部</a>
	</div>
</footer>


<amp-analytics id="4c2faa84438c" type="gtag"><script type="application/json">{"vars":{"gtag_id":"UA-154709495-1","config":{"UA-154709495-1":{"groups":"default"}}}}</script></amp-analytics>
</body>
</html>
<!-- This is the static html file -->